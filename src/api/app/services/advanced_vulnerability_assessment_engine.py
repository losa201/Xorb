"""
Advanced Vulnerability Assessment Engine
Real-world security scanner integration with AI-powered vulnerability analysis and exploitation assessment
"""

import asyncio
import json
import logging
import numpy as np
import subprocess
import tempfile
import os
import xml.etree.ElementTree as ET
import re
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Union, Tuple
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
import uuid
import aiofiles
import aiohttp

try:
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.preprocessing import StandardScaler
    from sklearn.metrics.pairwise import cosine_similarity
    import joblib
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False
    logging.warning("scikit-learn not available for ML vulnerability assessment")

from .interfaces import SecurityService
from .base_service import XORBService, ServiceType
from ..domain.entities import User, Organization


class VulnerabilitySeverity(Enum):
    """Vulnerability severity levels aligned with CVSS"""
    CRITICAL = "critical"      # 9.0-10.0
    HIGH = "high"             # 7.0-8.9
    MEDIUM = "medium"         # 4.0-6.9
    LOW = "low"              # 0.1-3.9
    INFORMATIONAL = "info"    # 0.0


class ExploitabilityLevel(Enum):
    """Exploitability assessment levels"""
    FUNCTIONAL = "functional"    # Working public exploits
    POC = "poc"                 # Proof of concept available
    THEORETICAL = "theoretical" # Theoretical exploitation
    UNKNOWN = "unknown"         # No exploitation info


class VulnerabilityCategory(Enum):
    """Vulnerability categories"""
    INJECTION = "injection"
    AUTHENTICATION = "authentication"
    AUTHORIZATION = "authorization"
    CRYPTOGRAPHY = "cryptography"
    CONFIGURATION = "configuration"
    NETWORK = "network"
    APPLICATION = "application"
    SYSTEM = "system"
    WEB = "web"
    UNKNOWN = "unknown"


@dataclass
class CVEData:
    """CVE (Common Vulnerabilities and Exposures) data"""
    cve_id: str
    description: str
    cvss_score: float
    cvss_vector: str
    severity: VulnerabilitySeverity
    published_date: datetime
    modified_date: datetime
    cwe_ids: List[str] = field(default_factory=list)
    references: List[str] = field(default_factory=list)
    vendor: Optional[str] = None
    product: Optional[str] = None
    affected_versions: List[str] = field(default_factory=list)


@dataclass
class ExploitData:
    """Exploit information"""
    exploit_id: str
    title: str
    type: str  # remote, local, dos, etc.
    platform: str
    date_published: datetime
    author: str
    verified: bool
    exploitability: ExploitabilityLevel
    exploit_code_url: Optional[str] = None
    metasploit_module: Optional[str] = None


@dataclass
class VulnerabilityFinding:
    """Comprehensive vulnerability finding"""
    id: str
    title: str
    description: str
    severity: VulnerabilitySeverity
    cvss_score: float
    cvss_vector: Optional[str]
    category: VulnerabilityCategory
    cve_data: List[CVEData] = field(default_factory=list)
    exploit_data: List[ExploitData] = field(default_factory=list)
    affected_hosts: List[str] = field(default_factory=list)
    affected_ports: List[int] = field(default_factory=list)
    affected_services: List[str] = field(default_factory=list)
    proof_of_concept: str = ""
    remediation: str = ""
    references: List[str] = field(default_factory=list)
    discovered_by: str = ""
    discovery_method: str = ""
    confidence: float = 0.0
    exploitability_score: float = 0.0
    business_impact: str = ""
    technical_impact: str = ""
    discovered_at: datetime = field(default_factory=datetime.utcnow)
    verified: bool = False
    false_positive_likelihood: float = 0.0

    def to_dict(self) -> Dict[str, Any]:
        return {
            "id": self.id,
            "title": self.title,
            "description": self.description,
            "severity": self.severity.value,
            "cvss_score": self.cvss_score,
            "cvss_vector": self.cvss_vector,
            "category": self.category.value,
            "cve_data": [cve.__dict__ for cve in self.cve_data],
            "exploit_data": [exp.__dict__ for exp in self.exploit_data],
            "affected_hosts": self.affected_hosts,
            "affected_ports": self.affected_ports,
            "affected_services": self.affected_services,
            "proof_of_concept": self.proof_of_concept,
            "remediation": self.remediation,
            "references": self.references,
            "discovered_by": self.discovered_by,
            "discovery_method": self.discovery_method,
            "confidence": self.confidence,
            "exploitability_score": self.exploitability_score,
            "business_impact": self.business_impact,
            "technical_impact": self.technical_impact,
            "discovered_at": self.discovered_at.isoformat(),
            "verified": self.verified,
            "false_positive_likelihood": self.false_positive_likelihood
        }


class SecurityTool:
    """Base class for security assessment tools"""

    def __init__(self, name: str, executable_path: str = None):
        self.name = name
        self.executable_path = executable_path or name
        self.logger = logging.getLogger(f"{__name__}.{name}")
        self.timeout = 300  # 5 minutes default

    async def is_available(self) -> bool:
        """Check if tool is available on system"""
        try:
            process = await asyncio.create_subprocess_exec(
                "which", self.executable_path,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            await process.wait()
            return process.returncode == 0
        except Exception:
            return False

    async def execute_command(self, args: List[str], timeout: Optional[int] = None) -> Tuple[str, str, int]:
        """Execute tool with security validation"""
        try:
            # Validate arguments
            validated_args = self._validate_arguments(args)
            cmd = [self.executable_path] + validated_args

            # Execute with timeout
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )

            stdout, stderr = await asyncio.wait_for(
                process.communicate(),
                timeout=timeout or self.timeout
            )

            return stdout.decode('utf-8'), stderr.decode('utf-8'), process.returncode

        except asyncio.TimeoutError:
            self.logger.error(f"Tool {self.name} execution timed out")
            if process:
                process.kill()
                await process.wait()
            raise
        except Exception as e:
            self.logger.error(f"Error executing {self.name}: {str(e)}")
            raise

    def _validate_arguments(self, args: List[str]) -> List[str]:
        """Validate and sanitize command arguments"""
        validated = []
        dangerous_chars = [';', '&', '|', '`', '$', '(', ')', '>', '<', '\n', '\r']

        for arg in args:
            # Check for dangerous characters
            if any(char in arg for char in dangerous_chars):
                self.logger.warning(f"Dangerous argument filtered: {arg}")
                continue

            # Limit argument length
            if len(arg) > 1000:
                self.logger.warning(f"Argument too long, truncated: {arg[:50]}...")
                arg = arg[:1000]

            validated.append(arg)

        return validated


class NmapVulnerabilityScanner(SecurityTool):
    """Advanced Nmap vulnerability scanner"""

    def __init__(self):
        super().__init__("nmap")
        self.vuln_scripts = [
            "vuln", "exploit", "auth", "brute", "discovery",
            "dos", "fuzzer", "intrusive", "malware", "safe"
        ]

    async def scan_vulnerabilities(self, targets: List[str], ports: List[int] = None) -> Dict[str, Any]:
        """Perform comprehensive vulnerability scan with Nmap"""
        try:
            results = {}

            for target in targets:
                target_results = await self._scan_single_target(target, ports)
                results[target] = target_results

            return {
                "tool": "nmap",
                "scan_type": "vulnerability",
                "results": results,
                "timestamp": datetime.utcnow().isoformat()
            }

        except Exception as e:
            self.logger.error(f"Nmap vulnerability scan failed: {str(e)}")
            return {"error": str(e), "tool": "nmap"}

    async def _scan_single_target(self, target: str, ports: List[int] = None) -> Dict[str, Any]:
        """Scan single target for vulnerabilities"""
        try:
            # Build Nmap command
            args = [
                "-sS",  # SYN scan
                "-sV",  # Version detection
                "-O",   # OS detection
                "--script", "vuln,exploit,auth",  # Vulnerability scripts
                "--script-args", "unsafe=1",  # Include potentially unsafe scripts
                "-T4",  # Timing template (aggressive)
                "--max-retries", "2",
                "-oX", "-",  # XML output to stdout
                target
            ]

            # Add port specification if provided
            if ports:
                port_str = ",".join(map(str, ports))
                args.extend(["-p", port_str])
            else:
                args.extend(["-p", "1-65535"])  # Full port scan

            # Execute scan
            stdout, stderr, returncode = await self.execute_command(args, timeout=600)

            if returncode != 0:
                self.logger.warning(f"Nmap scan completed with warnings: {stderr}")

            # Parse XML output
            vulnerabilities = self._parse_nmap_xml(stdout)

            return {
                "vulnerabilities": vulnerabilities,
                "raw_output": stdout,
                "scan_status": "completed" if returncode == 0 else "completed_with_errors"
            }

        except Exception as e:
            self.logger.error(f"Error scanning target {target}: {str(e)}")
            return {"error": str(e), "scan_status": "failed"}

    def _parse_nmap_xml(self, xml_output: str) -> List[Dict[str, Any]]:
        """Parse Nmap XML output for vulnerabilities"""
        vulnerabilities = []

        try:
            root = ET.fromstring(xml_output)

            for host in root.findall('host'):
                host_ip = None

                # Get host IP
                address = host.find('address')
                if address is not None:
                    host_ip = address.get('addr')

                # Parse ports and scripts
                ports = host.find('ports')
                if ports is not None:
                    for port in ports.findall('port'):
                        port_id = port.get('portid')
                        protocol = port.get('protocol')

                        # Check for vulnerable scripts
                        for script in port.findall('.//script'):
                            script_id = script.get('id')
                            script_output = script.get('output', '')

                            # Parse vulnerability information
                            vuln_info = self._parse_script_output(script_id, script_output, host_ip, port_id)
                            if vuln_info:
                                vulnerabilities.append(vuln_info)

                # Parse host scripts
                hostscript = host.find('hostscript')
                if hostscript is not None:
                    for script in hostscript.findall('script'):
                        script_id = script.get('id')
                        script_output = script.get('output', '')

                        vuln_info = self._parse_script_output(script_id, script_output, host_ip, None)
                        if vuln_info:
                            vulnerabilities.append(vuln_info)

        except ET.ParseError as e:
            self.logger.error(f"Error parsing Nmap XML: {str(e)}")
        except Exception as e:
            self.logger.error(f"Error processing Nmap results: {str(e)}")

        return vulnerabilities

    def _parse_script_output(self, script_id: str, output: str, host_ip: str, port: str) -> Optional[Dict[str, Any]]:
        """Parse individual script output for vulnerability information"""
        try:
            # Known vulnerability scripts
            vuln_scripts = {
                'ssl-poodle': {'severity': 'medium', 'category': 'cryptography'},
                'ssl-heartbleed': {'severity': 'high', 'category': 'cryptography'},
                'smb-vuln-ms17-010': {'severity': 'critical', 'category': 'system'},
                'smb-vuln-ms08-067': {'severity': 'critical', 'category': 'system'},
                'http-vuln-cve2017-5638': {'severity': 'critical', 'category': 'web'},
                'ssh-brute': {'severity': 'medium', 'category': 'authentication'},
                'ftp-anon': {'severity': 'medium', 'category': 'authentication'},
                'ms-sql-empty-password': {'severity': 'high', 'category': 'authentication'}
            }

            if script_id in vuln_scripts:
                script_info = vuln_scripts[script_id]

                # Extract CVE IDs if present
                cve_matches = re.findall(r'CVE-\d{4}-\d{4,7}', output)

                return {
                    "script_id": script_id,
                    "vulnerability_name": script_id.replace('-', ' ').title(),
                    "severity": script_info['severity'],
                    "category": script_info['category'],
                    "description": output.split('\n')[0] if output else "Vulnerability detected",
                    "affected_host": host_ip,
                    "affected_port": port,
                    "cve_ids": cve_matches,
                    "raw_output": output,
                    "discovery_method": "nmap_script"
                }

            # Check for generic vulnerability indicators
            vuln_indicators = ['vulnerable', 'exploitable', 'weak', 'insecure', 'CVE-']
            if any(indicator.lower() in output.lower() for indicator in vuln_indicators):
                return {
                    "script_id": script_id,
                    "vulnerability_name": f"Potential vulnerability detected by {script_id}",
                    "severity": "low",
                    "category": "unknown",
                    "description": output.split('\n')[0] if output else "Potential vulnerability",
                    "affected_host": host_ip,
                    "affected_port": port,
                    "cve_ids": re.findall(r'CVE-\d{4}-\d{4,7}', output),
                    "raw_output": output,
                    "discovery_method": "nmap_script"
                }

            return None

        except Exception as e:
            self.logger.error(f"Error parsing script output: {str(e)}")
            return None


class NucleiVulnerabilityScanner(SecurityTool):
    """Advanced Nuclei vulnerability scanner"""

    def __init__(self):
        super().__init__("nuclei")
        self.template_categories = [
            "cves", "exposures", "vulnerabilities", "misconfiguration",
            "technologies", "takeovers", "fuzzing", "file"
        ]

    async def scan_vulnerabilities(self, targets: List[str]) -> Dict[str, Any]:
        """Perform comprehensive vulnerability scan with Nuclei"""
        try:
            # Update templates first
            await self._update_templates()

            results = {}

            for target in targets:
                target_results = await self._scan_single_target(target)
                results[target] = target_results

            return {
                "tool": "nuclei",
                "scan_type": "vulnerability",
                "results": results,
                "timestamp": datetime.utcnow().isoformat()
            }

        except Exception as e:
            self.logger.error(f"Nuclei vulnerability scan failed: {str(e)}")
            return {"error": str(e), "tool": "nuclei"}

    async def _update_templates(self):
        """Update Nuclei templates"""
        try:
            await self.execute_command(["-update-templates"], timeout=120)
            self.logger.info("Nuclei templates updated successfully")
        except Exception as e:
            self.logger.warning(f"Could not update Nuclei templates: {str(e)}")

    async def _scan_single_target(self, target: str) -> Dict[str, Any]:
        """Scan single target with Nuclei"""
        try:
            args = [
                "-target", target,
                "-json",  # JSON output
                "-silent",  # Reduce output noise
                "-severity", "critical,high,medium,low",
                "-timeout", "10",
                "-retries", "2",
                "-rate-limit", "100"  # Requests per second
            ]

            # Execute scan
            stdout, stderr, returncode = await self.execute_command(args, timeout=600)

            # Parse JSON output
            vulnerabilities = self._parse_nuclei_output(stdout, target)

            return {
                "vulnerabilities": vulnerabilities,
                "raw_output": stdout,
                "scan_status": "completed" if returncode == 0 else "completed_with_errors"
            }

        except Exception as e:
            self.logger.error(f"Error scanning target {target} with Nuclei: {str(e)}")
            return {"error": str(e), "scan_status": "failed"}

    def _parse_nuclei_output(self, json_output: str, target: str) -> List[Dict[str, Any]]:
        """Parse Nuclei JSON output"""
        vulnerabilities = []

        try:
            for line in json_output.strip().split('\n'):
                if not line.strip():
                    continue

                try:
                    result = json.loads(line)

                    vuln = {
                        "template_id": result.get("template-id", "unknown"),
                        "vulnerability_name": result.get("info", {}).get("name", "Unknown"),
                        "severity": result.get("info", {}).get("severity", "low"),
                        "category": self._categorize_nuclei_template(result.get("template-id", "")),
                        "description": result.get("info", {}).get("description", ""),
                        "affected_host": target,
                        "affected_url": result.get("matched-at", ""),
                        "matcher_name": result.get("matcher-name", ""),
                        "extracted_results": result.get("extracted-results", []),
                        "curl_command": result.get("curl-command", ""),
                        "discovery_method": "nuclei_template",
                        "template_tags": result.get("info", {}).get("tags", []),
                        "reference": result.get("info", {}).get("reference", [])
                    }

                    vulnerabilities.append(vuln)

                except json.JSONDecodeError:
                    continue

        except Exception as e:
            self.logger.error(f"Error parsing Nuclei output: {str(e)}")

        return vulnerabilities

    def _categorize_nuclei_template(self, template_id: str) -> str:
        """Categorize Nuclei template by ID"""
        if any(keyword in template_id.lower() for keyword in ['cve-', 'vuln']):
            return "vulnerability"
        elif any(keyword in template_id.lower() for keyword in ['xss', 'sqli', 'injection']):
            return "injection"
        elif any(keyword in template_id.lower() for keyword in ['auth', 'login', 'bypass']):
            return "authentication"
        elif any(keyword in template_id.lower() for keyword in ['config', 'misconfig']):
            return "configuration"
        elif any(keyword in template_id.lower() for keyword in ['ssl', 'tls', 'crypto']):
            return "cryptography"
        else:
            return "unknown"


class VulnerabilityAssessmentML:
    """Machine Learning models for vulnerability assessment enhancement"""

    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.models_loaded = False

        # ML Models
        self.severity_classifier = None
        self.exploitability_predictor = None
        self.false_positive_detector = None
        self.feature_scaler = None

        # Model cache
        self.model_cache_dir = Path("./cache/vulnerability_models")
        self.model_cache_dir.mkdir(parents=True, exist_ok=True)

        # Initialize models lazily - will be initialized when first used
        self._models_initialization_started = False

    async def _ensure_models_initialized(self):
        """Ensure ML models are initialized"""
        if not self._models_initialization_started and SKLEARN_AVAILABLE:
            self._models_initialization_started = True
            await self._initialize_models()

    async def _initialize_models(self):
        """Initialize ML models for vulnerability assessment"""
        try:
            # Load or create models
            await self._load_or_create_models()
            self.models_loaded = True
            self.logger.info("✅ Vulnerability assessment ML models loaded")

        except Exception as e:
            self.logger.error(f"Error initializing ML models: {str(e)}")
            self.models_loaded = False

    async def _load_or_create_models(self):
        """Load existing models or create new ones"""
        try:
            # Try to load existing models
            severity_model_path = self.model_cache_dir / "severity_classifier.joblib"
            exploit_model_path = self.model_cache_dir / "exploitability_predictor.joblib"
            fp_model_path = self.model_cache_dir / "false_positive_detector.joblib"
            scaler_path = self.model_cache_dir / "feature_scaler.joblib"

            if all(path.exists() for path in [severity_model_path, exploit_model_path, fp_model_path, scaler_path]):
                # Load existing models
                self.severity_classifier = joblib.load(severity_model_path)
                self.exploitability_predictor = joblib.load(exploit_model_path)
                self.false_positive_detector = joblib.load(fp_model_path)
                self.feature_scaler = joblib.load(scaler_path)
                self.logger.info("Loaded existing ML models from cache")
            else:
                # Create and train new models
                await self._create_and_train_models()

        except Exception as e:
            self.logger.error(f"Error loading/creating models: {str(e)}")
            await self._create_fallback_models()

    async def _create_and_train_models(self):
        """Create and train new ML models"""
        try:
            # Create models
            self.severity_classifier = RandomForestClassifier(
                n_estimators=100, random_state=42, max_depth=10
            )
            self.exploitability_predictor = RandomForestClassifier(
                n_estimators=100, random_state=42, max_depth=8
            )
            self.false_positive_detector = RandomForestClassifier(
                n_estimators=100, random_state=42, max_depth=6
            )
            self.feature_scaler = StandardScaler()

            # Generate training data
            training_data = self._generate_training_data()

            if training_data:
                X, y_severity, y_exploit, y_fp = training_data

                # Scale features
                X_scaled = self.feature_scaler.fit_transform(X)

                # Train models
                self.severity_classifier.fit(X_scaled, y_severity)
                self.exploitability_predictor.fit(X_scaled, y_exploit)
                self.false_positive_detector.fit(X_scaled, y_fp)

                # Save models
                await self._save_models()

                self.logger.info("Created and trained new ML models")

        except Exception as e:
            self.logger.error(f"Error creating models: {str(e)}")
            await self._create_fallback_models()

    async def _create_fallback_models(self):
        """Create basic fallback models"""
        try:
            self.severity_classifier = RandomForestClassifier(n_estimators=10, random_state=42)
            self.exploitability_predictor = RandomForestClassifier(n_estimators=10, random_state=42)
            self.false_positive_detector = RandomForestClassifier(n_estimators=10, random_state=42)
            self.feature_scaler = StandardScaler()

            # Minimal training with dummy data
            X_dummy = np.random.random((50, 15))
            y_dummy = np.random.choice(['low', 'medium', 'high'], 50)

            X_scaled = self.feature_scaler.fit_transform(X_dummy)
            self.severity_classifier.fit(X_scaled, y_dummy)
            self.exploitability_predictor.fit(X_scaled, y_dummy)
            self.false_positive_detector.fit(X_scaled, y_dummy)

            self.logger.info("Created fallback ML models")

        except Exception as e:
            self.logger.error(f"Error creating fallback models: {str(e)}")

    def _generate_training_data(self) -> Optional[Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]]:
        """Generate synthetic training data for vulnerability assessment"""
        try:
            # Synthetic vulnerability data
            n_samples = 1000
            features = []
            severity_labels = []
            exploit_labels = []
            fp_labels = []

            # Define vulnerability patterns
            vuln_patterns = {
                'critical': {
                    'cvss_base': 9.0, 'exploit_available': 0.8, 'public_exploit': 0.7,
                    'network_access': 0.9, 'auth_required': 0.1, 'complexity': 0.2
                },
                'high': {
                    'cvss_base': 7.5, 'exploit_available': 0.6, 'public_exploit': 0.4,
                    'network_access': 0.7, 'auth_required': 0.3, 'complexity': 0.4
                },
                'medium': {
                    'cvss_base': 5.0, 'exploit_available': 0.3, 'public_exploit': 0.2,
                    'network_access': 0.5, 'auth_required': 0.6, 'complexity': 0.6
                },
                'low': {
                    'cvss_base': 2.0, 'exploit_available': 0.1, 'public_exploit': 0.05,
                    'network_access': 0.3, 'auth_required': 0.8, 'complexity': 0.8
                }
            }

            for _ in range(n_samples):
                severity = np.random.choice(['critical', 'high', 'medium', 'low'])
                pattern = vuln_patterns[severity]

                # Generate features with noise
                feature_vector = []
                for key, base_value in pattern.items():
                    noise = np.random.normal(0, 0.1)
                    value = max(0, min(1, base_value + noise))
                    feature_vector.append(value)

                # Add additional synthetic features
                feature_vector.extend([
                    np.random.random(),  # port_exposure
                    np.random.random(),  # service_version_old
                    np.random.random(),  # config_weakness
                    np.random.random(),  # patch_availability
                    np.random.random(),  # vendor_response
                    np.random.random(),  # attack_vector_complexity
                    np.random.random(),  # impact_confidentiality
                    np.random.random(),  # impact_integrity
                    np.random.random()   # impact_availability
                ])

                features.append(feature_vector)
                severity_labels.append(severity)

                # Generate exploit labels based on severity
                exploit_prob = pattern['exploit_available']
                exploit_labels.append('high' if np.random.random() < exploit_prob else 'low')

                # Generate false positive labels
                fp_prob = 0.1 if severity in ['critical', 'high'] else 0.3
                fp_labels.append('true' if np.random.random() < fp_prob else 'false')

            return (
                np.array(features),
                np.array(severity_labels),
                np.array(exploit_labels),
                np.array(fp_labels)
            )

        except Exception as e:
            self.logger.error(f"Error generating training data: {str(e)}")
            return None

    async def _save_models(self):
        """Save trained models to cache"""
        try:
            joblib.dump(self.severity_classifier, self.model_cache_dir / "severity_classifier.joblib")
            joblib.dump(self.exploitability_predictor, self.model_cache_dir / "exploitability_predictor.joblib")
            joblib.dump(self.false_positive_detector, self.model_cache_dir / "false_positive_detector.joblib")
            joblib.dump(self.feature_scaler, self.model_cache_dir / "feature_scaler.joblib")

        except Exception as e:
            self.logger.error(f"Error saving models: {str(e)}")

    async def enhance_vulnerability_finding(self, finding: Dict[str, Any]) -> VulnerabilityFinding:
        """Enhance vulnerability finding with ML analysis"""
        try:
            # Ensure ML models are initialized
            await self._ensure_models_initialized()

            # Extract features from finding
            features = self._extract_vulnerability_features(finding)

            # Default values
            enhanced_severity = finding.get('severity', 'low')
            exploitability_score = 0.0
            false_positive_likelihood = 0.5
            confidence = 0.5

            if self.models_loaded:
                try:
                    # Scale features
                    feature_vector = np.array([list(features.values())])
                    scaled_features = self.feature_scaler.transform(feature_vector)

                    # Predict severity
                    severity_pred = self.severity_classifier.predict(scaled_features)[0]
                    severity_proba = self.severity_classifier.predict_proba(scaled_features)[0]

                    # Predict exploitability
                    exploit_pred = self.exploitability_predictor.predict_proba(scaled_features)[0]
                    exploitability_score = max(exploit_pred) if len(exploit_pred) > 0 else 0.0

                    # Predict false positive likelihood
                    fp_pred = self.false_positive_detector.predict_proba(scaled_features)[0]
                    false_positive_likelihood = fp_pred[1] if len(fp_pred) > 1 else 0.5

                    # Update severity if ML confidence is high
                    if max(severity_proba) > 0.7:
                        enhanced_severity = severity_pred
                        confidence = max(severity_proba)

                except Exception as e:
                    self.logger.warning(f"ML enhancement failed: {str(e)}")

            # Create enhanced finding
            enhanced_finding = VulnerabilityFinding(
                id=finding.get('id', str(uuid.uuid4())),
                title=finding.get('vulnerability_name', 'Unknown Vulnerability'),
                description=finding.get('description', ''),
                severity=VulnerabilitySeverity(enhanced_severity),
                cvss_score=self._calculate_cvss_score(enhanced_severity),
                cvss_vector=finding.get('cvss_vector'),
                category=VulnerabilityCategory(finding.get('category', 'unknown')),
                affected_hosts=[finding.get('affected_host', '')],
                affected_ports=[int(finding.get('affected_port', 0))] if finding.get('affected_port') else [],
                affected_services=[finding.get('affected_service', '')],
                proof_of_concept=finding.get('raw_output', ''),
                remediation=self._generate_remediation(finding),
                references=finding.get('reference', []),
                discovered_by=finding.get('discovery_method', 'unknown'),
                discovery_method=finding.get('discovery_method', 'automated'),
                confidence=confidence,
                exploitability_score=exploitability_score,
                business_impact=self._assess_business_impact(enhanced_severity),
                technical_impact=self._assess_technical_impact(enhanced_severity),
                false_positive_likelihood=false_positive_likelihood
            )

            return enhanced_finding

        except Exception as e:
            self.logger.error(f"Error enhancing vulnerability finding: {str(e)}")
            # Return basic finding
            return VulnerabilityFinding(
                id=str(uuid.uuid4()),
                title=finding.get('vulnerability_name', 'Unknown Vulnerability'),
                description=finding.get('description', ''),
                severity=VulnerabilitySeverity(finding.get('severity', 'low')),
                cvss_score=0.0,
                cvss_vector=None,
                category=VulnerabilityCategory.UNKNOWN
            )

    def _extract_vulnerability_features(self, finding: Dict[str, Any]) -> Dict[str, float]:
        """Extract ML features from vulnerability finding"""
        features = {}

        try:
            # Severity-based features
            severity_map = {'critical': 1.0, 'high': 0.75, 'medium': 0.5, 'low': 0.25}
            features['severity_score'] = severity_map.get(finding.get('severity', 'low'), 0.25)

            # Port and service features
            port = finding.get('affected_port', 0)
            if isinstance(port, str):
                try:
                    port = int(port)
                except ValueError:
                    port = 0

            features['port_exposure'] = 1.0 if port in [21, 22, 23, 25, 53, 80, 443, 993, 995] else 0.0
            features['high_risk_port'] = 1.0 if port in [21, 23, 135, 139, 445] else 0.0

            # CVE features
            cve_ids = finding.get('cve_ids', [])
            features['has_cve'] = 1.0 if cve_ids else 0.0
            features['cve_count'] = min(len(cve_ids) / 5.0, 1.0)  # Normalize to 0-1

            # Discovery method features
            discovery_method = finding.get('discovery_method', '')
            features['discovered_by_nmap'] = 1.0 if 'nmap' in discovery_method else 0.0
            features['discovered_by_nuclei'] = 1.0 if 'nuclei' in discovery_method else 0.0

            # Template/script features
            template_id = finding.get('template_id', finding.get('script_id', ''))
            features['exploit_template'] = 1.0 if 'exploit' in template_id.lower() else 0.0
            features['auth_issue'] = 1.0 if 'auth' in template_id.lower() else 0.0

            # Content analysis features
            content = str(finding.get('description', '') + finding.get('raw_output', ''))
            features['mentions_exploit'] = 1.0 if 'exploit' in content.lower() else 0.0
            features['mentions_rce'] = 1.0 if any(term in content.lower() for term in ['rce', 'remote code', 'command execution']) else 0.0
            features['mentions_sqli'] = 1.0 if 'sql' in content.lower() else 0.0
            features['mentions_xss'] = 1.0 if 'xss' in content.lower() else 0.0

            # Category features
            category = finding.get('category', 'unknown')
            features['crypto_vuln'] = 1.0 if category == 'cryptography' else 0.0
            features['auth_vuln'] = 1.0 if category == 'authentication' else 0.0
            features['injection_vuln'] = 1.0 if category == 'injection' else 0.0

        except Exception as e:
            self.logger.error(f"Error extracting features: {str(e)}")
            # Return default features
            features = {f'feature_{i}': 0.0 for i in range(15)}

        return features

    def _calculate_cvss_score(self, severity: str) -> float:
        """Calculate CVSS score based on severity"""
        severity_scores = {
            'critical': 9.5,
            'high': 7.8,
            'medium': 5.5,
            'low': 2.8,
            'info': 0.0
        }
        return severity_scores.get(severity, 2.8)

    def _generate_remediation(self, finding: Dict[str, Any]) -> str:
        """Generate remediation advice based on vulnerability"""
        try:
            template_id = finding.get('template_id', finding.get('script_id', ''))
            category = finding.get('category', 'unknown')

            # Category-based remediation
            remediation_templates = {
                'authentication': 'Implement strong authentication mechanisms, disable default credentials, and enforce password policies.',
                'cryptography': 'Update to secure cryptographic protocols, disable weak ciphers, and implement proper certificate management.',
                'injection': 'Implement input validation, use parameterized queries, and apply principle of least privilege.',
                'configuration': 'Review and harden system configuration, remove unnecessary services, and apply security baselines.',
                'network': 'Implement network segmentation, apply firewall rules, and monitor network traffic.',
                'web': 'Apply web application security controls, implement WAF, and conduct security code review.'
            }

            base_remediation = remediation_templates.get(category, 'Apply security patches and follow vendor security recommendations.')

            # Specific remediation based on template
            if 'ssl' in template_id.lower():
                base_remediation += ' Update SSL/TLS configuration and disable deprecated protocols.'
            elif 'smb' in template_id.lower():
                base_remediation += ' Apply SMB security patches and disable SMBv1.'
            elif 'ssh' in template_id.lower():
                base_remediation += ' Configure SSH security settings and implement key-based authentication.'

            return base_remediation

        except Exception:
            return 'Review vulnerability details and apply appropriate security measures.'

    def _assess_business_impact(self, severity: str) -> str:
        """Assess business impact based on severity"""
        impact_map = {
            'critical': 'SEVERE: Potential for complete system compromise, data breach, and business disruption',
            'high': 'HIGH: Significant risk of unauthorized access and potential data exposure',
            'medium': 'MODERATE: Limited risk of security compromise with potential for privilege escalation',
            'low': 'LOW: Minimal direct security impact, may facilitate other attacks',
            'info': 'INFORMATIONAL: No direct security impact, provides reconnaissance information'
        }
        return impact_map.get(severity, 'UNKNOWN: Impact assessment required')

    def _assess_technical_impact(self, severity: str) -> str:
        """Assess technical impact based on severity"""
        impact_map = {
            'critical': 'Complete system compromise, arbitrary code execution, full data access',
            'high': 'Significant system access, potential privilege escalation, sensitive data exposure',
            'medium': 'Limited system access, information disclosure, service disruption',
            'low': 'Minor information disclosure, limited functionality impact',
            'info': 'Information gathering, no direct system impact'
        }
        return impact_map.get(severity, 'Technical impact requires assessment')


class AdvancedVulnerabilityAssessmentEngine(SecurityService, XORBService):
    """
    Advanced vulnerability assessment engine with real-world security tool integration
    and AI-powered vulnerability analysis capabilities
    """

    def __init__(self):
        super().__init__(
            service_id="advanced_vulnerability_assessment",
            service_type=ServiceType.SECURITY_TESTING
        )
        self.logger = logging.getLogger(__name__)

        # Initialize security scanners
        self.nmap_scanner = NmapVulnerabilityScanner()
        self.nuclei_scanner = NucleiVulnerabilityScanner()

        # Initialize ML engine
        self.ml_engine = VulnerabilityAssessmentML()

        # Vulnerability database cache
        self._vulnerability_cache: Dict[str, VulnerabilityFinding] = {}

        self.logger.info("✅ Advanced Vulnerability Assessment Engine initialized")

    async def comprehensive_vulnerability_assessment(
        self,
        targets: List[str],
        ports: List[int] = None,
        assessment_type: str = "comprehensive"
    ) -> Dict[str, Any]:
        """Perform comprehensive vulnerability assessment"""
        try:
            assessment_id = str(uuid.uuid4())
            start_time = datetime.utcnow()

            self.logger.info(f"Starting comprehensive vulnerability assessment {assessment_id} for {len(targets)} targets")

            # Initialize results
            results = {
                "assessment_id": assessment_id,
                "start_time": start_time.isoformat(),
                "targets": targets,
                "assessment_type": assessment_type,
                "scanners_used": [],
                "vulnerabilities": [],
                "summary": {},
                "recommendations": []
            }

            # Check scanner availability
            nmap_available = await self.nmap_scanner.is_available()
            nuclei_available = await self.nuclei_scanner.is_available()

            if not nmap_available and not nuclei_available:
                raise Exception("No vulnerability scanners available")

            # Phase 1: Nmap vulnerability scanning
            if nmap_available:
                self.logger.info("Phase 1: Nmap vulnerability scanning")
                results["scanners_used"].append("nmap")

                nmap_results = await self.nmap_scanner.scan_vulnerabilities(targets, ports)

                # Process Nmap results
                for target, target_results in nmap_results.get("results", {}).items():
                    for vuln_data in target_results.get("vulnerabilities", []):
                        enhanced_vuln = await self.ml_engine.enhance_vulnerability_finding(vuln_data)
                        results["vulnerabilities"].append(enhanced_vuln.to_dict())

            # Phase 2: Nuclei vulnerability scanning
            if nuclei_available:
                self.logger.info("Phase 2: Nuclei vulnerability scanning")
                results["scanners_used"].append("nuclei")

                nuclei_results = await self.nuclei_scanner.scan_vulnerabilities(targets)

                # Process Nuclei results
                for target, target_results in nuclei_results.get("results", {}).items():
                    for vuln_data in target_results.get("vulnerabilities", []):
                        enhanced_vuln = await self.ml_engine.enhance_vulnerability_finding(vuln_data)
                        results["vulnerabilities"].append(enhanced_vuln.to_dict())

            # Phase 3: Post-processing and analysis
            self.logger.info("Phase 3: Post-processing and vulnerability analysis")

            # Deduplicate and correlate vulnerabilities
            deduplicated_vulns = self._deduplicate_vulnerabilities(results["vulnerabilities"])
            results["vulnerabilities"] = deduplicated_vulns

            # Generate summary
            results["summary"] = self._generate_assessment_summary(deduplicated_vulns)

            # Generate recommendations
            results["recommendations"] = self._generate_assessment_recommendations(deduplicated_vulns)

            # Finalize results
            end_time = datetime.utcnow()
            results["end_time"] = end_time.isoformat()
            results["duration_seconds"] = (end_time - start_time).total_seconds()
            results["status"] = "completed"

            self.logger.info(f"Vulnerability assessment {assessment_id} completed in {results['duration_seconds']:.2f} seconds")
            self.logger.info(f"Found {len(results['vulnerabilities'])} vulnerabilities")

            return results

        except Exception as e:
            self.logger.error(f"Error in vulnerability assessment: {str(e)}")
            return {
                "assessment_id": str(uuid.uuid4()),
                "error": str(e),
                "status": "failed",
                "timestamp": datetime.utcnow().isoformat()
            }

    async def analyze_security_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Analyze security data for vulnerabilities"""
        try:
            # Extract targets from security data
            targets = []

            if "hosts" in data:
                targets.extend(data["hosts"])
            elif "targets" in data:
                targets.extend(data["targets"])
            elif "ip_addresses" in data:
                targets.extend(data["ip_addresses"])

            if not targets:
                return {"error": "No targets found in security data"}

            # Perform vulnerability assessment
            assessment_type = data.get("assessment_type", "targeted")
            results = await self.comprehensive_vulnerability_assessment(targets, assessment_type=assessment_type)

            return results

        except Exception as e:
            self.logger.error(f"Error analyzing security data: {str(e)}")
            return {"error": str(e)}

    async def assess_risk(self, context: Dict[str, Any]) -> float:
        """Assess risk level for given context"""
        try:
            # Extract vulnerability information from context
            vulnerabilities = context.get("vulnerabilities", [])

            if not vulnerabilities:
                return 0.0

            # Calculate risk score based on vulnerabilities
            risk_score = 0.0
            total_weight = 0.0

            severity_weights = {
                "critical": 1.0,
                "high": 0.8,
                "medium": 0.5,
                "low": 0.2,
                "informational": 0.1
            }

            for vuln in vulnerabilities:
                severity = vuln.get("severity", "low")
                confidence = vuln.get("confidence", 0.5)
                exploitability = vuln.get("exploitability_score", 0.0)

                weight = severity_weights.get(severity, 0.2)
                vuln_score = weight * confidence * (1 + exploitability)

                risk_score += vuln_score
                total_weight += weight

            # Normalize risk score
            if total_weight > 0:
                normalized_score = min(1.0, risk_score / total_weight)
            else:
                normalized_score = 0.0

            return round(normalized_score, 3)

        except Exception as e:
            self.logger.error(f"Error assessing risk: {str(e)}")
            return 0.0

    def _deduplicate_vulnerabilities(self, vulnerabilities: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Deduplicate similar vulnerabilities"""
        try:
            unique_vulns = []
            seen_signatures = set()

            for vuln in vulnerabilities:
                # Create signature for deduplication
                signature = self._create_vulnerability_signature(vuln)

                if signature not in seen_signatures:
                    seen_signatures.add(signature)
                    unique_vulns.append(vuln)
                else:
                    # Merge with existing vulnerability
                    existing_vuln = next((v for v in unique_vulns if self._create_vulnerability_signature(v) == signature), None)
                    if existing_vuln:
                        existing_vuln = self._merge_vulnerabilities(existing_vuln, vuln)

            return unique_vulns

        except Exception as e:
            self.logger.error(f"Error deduplicating vulnerabilities: {str(e)}")
            return vulnerabilities

    def _create_vulnerability_signature(self, vuln: Dict[str, Any]) -> str:
        """Create signature for vulnerability deduplication"""
        try:
            # Use title, severity, and affected hosts for signature
            title = vuln.get("title", "").lower()
            severity = vuln.get("severity", "")
            hosts = ",".join(sorted(vuln.get("affected_hosts", [])))

            signature = f"{title}|{severity}|{hosts}"
            return hashlib.md5(signature.encode()).hexdigest()

        except Exception:
            return str(uuid.uuid4())

    def _merge_vulnerabilities(self, vuln1: Dict[str, Any], vuln2: Dict[str, Any]) -> Dict[str, Any]:
        """Merge similar vulnerabilities"""
        try:
            # Take the higher severity
            severity1 = vuln1.get("severity", "low")
            severity2 = vuln2.get("severity", "low")

            severity_order = ["informational", "low", "medium", "high", "critical"]
            if severity_order.index(severity2) > severity_order.index(severity1):
                vuln1["severity"] = severity2

            # Merge affected hosts and ports
            vuln1["affected_hosts"] = list(set(vuln1.get("affected_hosts", []) + vuln2.get("affected_hosts", [])))
            vuln1["affected_ports"] = list(set(vuln1.get("affected_ports", []) + vuln2.get("affected_ports", [])))

            # Take higher confidence
            vuln1["confidence"] = max(vuln1.get("confidence", 0.0), vuln2.get("confidence", 0.0))

            return vuln1

        except Exception as e:
            self.logger.error(f"Error merging vulnerabilities: {str(e)}")
            return vuln1

    def _generate_assessment_summary(self, vulnerabilities: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Generate assessment summary statistics"""
        try:
            summary = {
                "total_vulnerabilities": len(vulnerabilities),
                "severity_distribution": {},
                "category_distribution": {},
                "exploitability_distribution": {},
                "top_affected_hosts": {},
                "highest_risk_vulns": []
            }

            # Count by severity
            for vuln in vulnerabilities:
                severity = vuln.get("severity", "unknown")
                summary["severity_distribution"][severity] = summary["severity_distribution"].get(severity, 0) + 1

                category = vuln.get("category", "unknown")
                summary["category_distribution"][category] = summary["category_distribution"].get(category, 0) + 1

                exploitability = vuln.get("exploitability_score", 0.0)
                if exploitability > 0.7:
                    exploit_level = "high"
                elif exploitability > 0.4:
                    exploit_level = "medium"
                else:
                    exploit_level = "low"
                summary["exploitability_distribution"][exploit_level] = summary["exploitability_distribution"].get(exploit_level, 0) + 1

                # Count affected hosts
                for host in vuln.get("affected_hosts", []):
                    summary["top_affected_hosts"][host] = summary["top_affected_hosts"].get(host, 0) + 1

            # Get highest risk vulnerabilities
            high_risk_vulns = [v for v in vulnerabilities if v.get("severity") in ["critical", "high"]]
            high_risk_vulns.sort(key=lambda x: (x.get("cvss_score", 0), x.get("exploitability_score", 0)), reverse=True)
            summary["highest_risk_vulns"] = high_risk_vulns[:5]  # Top 5

            return summary

        except Exception as e:
            self.logger.error(f"Error generating summary: {str(e)}")
            return {"error": str(e)}

    def _generate_assessment_recommendations(self, vulnerabilities: List[Dict[str, Any]]) -> List[str]:
        """Generate assessment recommendations"""
        try:
            recommendations = []

            # Count critical and high severity vulnerabilities
            critical_count = len([v for v in vulnerabilities if v.get("severity") == "critical"])
            high_count = len([v for v in vulnerabilities if v.get("severity") == "high"])

            if critical_count > 0:
                recommendations.append(f"URGENT: Address {critical_count} critical vulnerabilities immediately")
                recommendations.append("Implement emergency incident response procedures")

            if high_count > 0:
                recommendations.append(f"HIGH PRIORITY: Remediate {high_count} high-severity vulnerabilities within 24-48 hours")

            # Category-specific recommendations
            categories = set([v.get("category") for v in vulnerabilities])

            if "injection" in categories:
                recommendations.append("Implement input validation and parameterized queries to prevent injection attacks")

            if "authentication" in categories:
                recommendations.append("Strengthen authentication mechanisms and implement multi-factor authentication")

            if "cryptography" in categories:
                recommendations.append("Update cryptographic implementations and disable weak cipher suites")

            if "configuration" in categories:
                recommendations.append("Review and harden system configurations according to security baselines")

            # General recommendations
            recommendations.extend([
                "Implement vulnerability management program with regular scanning",
                "Deploy intrusion detection and prevention systems",
                "Conduct security awareness training for staff",
                "Establish incident response and recovery procedures",
                "Implement network segmentation and access controls"
            ])

            return recommendations

        except Exception as e:
            self.logger.error(f"Error generating recommendations: {str(e)}")
            return ["Error generating recommendations - manual assessment required"]
