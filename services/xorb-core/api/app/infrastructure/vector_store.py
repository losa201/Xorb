"""Vector storage and similarity search with pgvector."""
import logging
from typing import Dict, List, Optional, Tuple
from uuid import UUID

import asyncpg
import numpy as np
from sqlalchemy import text
from sqlalchemy.ext.asyncio import AsyncSession

from .database import get_database_connection, get_async_session


logger = logging.getLogger(__name__)


class VectorStore:
    """High-performance vector storage with pgvector."""

    def __init__(self, dimension: int = 1536):  # OpenAI embedding dimension
        self.dimension = dimension

    async def create_vector_index(
        self,
        table_name: str = "embedding_vectors",
        vector_column: str = "embedding",
        index_type: str = "hnsw",
        m: int = 16,
        ef_construction: int = 64
    ) -> None:
        """Create HNSW index for vector similarity search."""

        index_name = f"idx_{table_name}_{vector_column}_{index_type}"

        # HNSW index for cosine similarity
        if index_type == "hnsw":
            index_sql = f"""
                CREATE INDEX IF NOT EXISTS {index_name}
                ON {table_name}
                USING hnsw ({vector_column} vector_cosine_ops)
                WITH (m = {m}, ef_construction = {ef_construction})
            """
        # IVFFlat index (alternative)
        elif index_type == "ivfflat":
            lists = min(max(int(np.sqrt(1000)), 10), 1000)  # Heuristic for lists
            index_sql = f"""
                CREATE INDEX IF NOT EXISTS {index_name}
                ON {table_name}
                USING ivfflat ({vector_column} vector_cosine_ops)
                WITH (lists = {lists})
            """
        else:
            raise ValueError(f"Unsupported index type: {index_type}")

        try:
            async with get_database_connection() as conn:
                await conn.execute(index_sql)
                logger.info(f"Created vector index {index_name} on {table_name}.{vector_column}")
        except Exception as e:
            logger.error(f"Failed to create vector index: {e}")
            raise

    async def add_vector(
        self,
        vector: List[float],
        tenant_id: UUID,
        source_type: str,
        source_id: UUID,
        content_hash: str,
        embedding_model: str,
        metadata: Optional[Dict] = None
    ) -> UUID:
        """Add vector to the store."""

        if len(vector) != self.dimension:
            raise ValueError(f"Vector dimension {len(vector)} doesn't match expected {self.dimension}")

        vector_id = UUID(int=0)  # Will be generated by database

        async with get_async_session() as session:
            # Set tenant context
            await session.execute(
                text("SELECT set_config('app.tenant_id', :tenant_id, false)"),
                {"tenant_id": str(tenant_id)}
            )

            # Insert vector
            insert_sql = text("""
                INSERT INTO embedding_vectors (
                    tenant_id, source_type, source_id, content_hash,
                    embedding_model, embedding, metadata
                ) VALUES (
                    :tenant_id, :source_type, :source_id, :content_hash,
                    :embedding_model, :embedding, :metadata
                ) RETURNING id
            """)

            result = await session.execute(insert_sql, {
                "tenant_id": tenant_id,
                "source_type": source_type,
                "source_id": source_id,
                "content_hash": content_hash,
                "embedding_model": embedding_model,
                "embedding": vector,
                "metadata": metadata or {}
            })

            vector_id = result.scalar()
            await session.commit()

        logger.debug(f"Added vector {vector_id} for {source_type}:{source_id}")
        return vector_id

    async def search_similar(
        self,
        query_vector: List[float],
        tenant_id: UUID,
        limit: int = 10,
        source_type: Optional[str] = None,
        similarity_threshold: float = 0.0,
        ef_search: Optional[int] = None
    ) -> List[Dict]:
        """Search for similar vectors using cosine similarity."""

        if len(query_vector) != self.dimension:
            raise ValueError(f"Query vector dimension {len(query_vector)} doesn't match expected {self.dimension}")

        # Set HNSW search parameters if specified
        set_params_sql = ""
        if ef_search:
            set_params_sql = f"SET hnsw.ef_search = {ef_search};"

        # Build search query
        where_clause = "WHERE tenant_id = :tenant_id"
        params = {"tenant_id": tenant_id, "query_vector": query_vector}

        if source_type:
            where_clause += " AND source_type = :source_type"
            params["source_type"] = source_type

        search_sql = f"""
            {set_params_sql}
            SELECT
                id,
                source_type,
                source_id,
                content_hash,
                embedding_model,
                metadata,
                1 - (embedding <=> :query_vector::vector) as similarity
            FROM embedding_vectors
            {where_clause}
            AND 1 - (embedding <=> :query_vector::vector) >= :similarity_threshold
            ORDER BY embedding <=> :query_vector::vector
            LIMIT :limit
        """

        params["similarity_threshold"] = similarity_threshold
        params["limit"] = limit

        results = []

        try:
            async with get_database_connection() as conn:
                # Set tenant context
                await conn.execute(
                    "SELECT set_config('app.tenant_id', $1, false)",
                    str(tenant_id)
                )

                rows = await conn.fetch(search_sql, **params)

                for row in rows:
                    results.append({
                        "id": row["id"],
                        "source_type": row["source_type"],
                        "source_id": row["source_id"],
                        "content_hash": row["content_hash"],
                        "embedding_model": row["embedding_model"],
                        "metadata": row["metadata"],
                        "similarity": float(row["similarity"])
                    })

        except Exception as e:
            logger.error(f"Vector search failed: {e}")
            raise

        logger.debug(f"Found {len(results)} similar vectors for tenant {tenant_id}")
        return results

    async def search_by_text(
        self,
        query_text: str,
        tenant_id: UUID,
        embedding_function: callable,
        limit: int = 10,
        source_type: Optional[str] = None,
        similarity_threshold: float = 0.0
    ) -> List[Dict]:
        """Search by text using embedding function."""

        # Generate embedding for query text
        query_vector = await embedding_function(query_text)

        return await self.search_similar(
            query_vector=query_vector,
            tenant_id=tenant_id,
            limit=limit,
            source_type=source_type,
            similarity_threshold=similarity_threshold
        )

    async def get_vector(
        self,
        vector_id: UUID,
        tenant_id: UUID
    ) -> Optional[Dict]:
        """Get vector by ID."""

        async with get_async_session() as session:
            # Set tenant context
            await session.execute(
                text("SELECT set_config('app.tenant_id', :tenant_id, false)"),
                {"tenant_id": str(tenant_id)}
            )

            query_sql = text("""
                SELECT
                    id, tenant_id, source_type, source_id,
                    content_hash, embedding_model, embedding, metadata,
                    created_at
                FROM embedding_vectors
                WHERE id = :vector_id
            """)

            result = await session.execute(query_sql, {"vector_id": vector_id})
            row = result.fetchone()

            if row:
                return {
                    "id": row.id,
                    "tenant_id": row.tenant_id,
                    "source_type": row.source_type,
                    "source_id": row.source_id,
                    "content_hash": row.content_hash,
                    "embedding_model": row.embedding_model,
                    "embedding": list(row.embedding),
                    "metadata": row.metadata,
                    "created_at": row.created_at.isoformat()
                }

        return None

    async def delete_vector(
        self,
        vector_id: UUID,
        tenant_id: UUID
    ) -> bool:
        """Delete vector by ID."""

        async with get_async_session() as session:
            # Set tenant context
            await session.execute(
                text("SELECT set_config('app.tenant_id', :tenant_id, false)"),
                {"tenant_id": str(tenant_id)}
            )

            delete_sql = text("""
                DELETE FROM embedding_vectors
                WHERE id = :vector_id AND tenant_id = :tenant_id
            """)

            result = await session.execute(delete_sql, {
                "vector_id": vector_id,
                "tenant_id": tenant_id
            })

            await session.commit()
            return result.rowcount > 0

    async def delete_vectors_by_source(
        self,
        source_id: UUID,
        tenant_id: UUID,
        source_type: Optional[str] = None
    ) -> int:
        """Delete all vectors for a source."""

        async with get_async_session() as session:
            # Set tenant context
            await session.execute(
                text("SELECT set_config('app.tenant_id', :tenant_id, false)"),
                {"tenant_id": str(tenant_id)}
            )

            where_clause = "WHERE source_id = :source_id AND tenant_id = :tenant_id"
            params = {"source_id": source_id, "tenant_id": tenant_id}

            if source_type:
                where_clause += " AND source_type = :source_type"
                params["source_type"] = source_type

            delete_sql = text(f"""
                DELETE FROM embedding_vectors
                {where_clause}
            """)

            result = await session.execute(delete_sql, params)
            await session.commit()

            return result.rowcount

    async def get_vector_stats(self, tenant_id: UUID) -> Dict:
        """Get vector statistics for tenant."""

        async with get_async_session() as session:
            # Set tenant context
            await session.execute(
                text("SELECT set_config('app.tenant_id', :tenant_id, false)"),
                {"tenant_id": str(tenant_id)}
            )

            stats_sql = text("""
                SELECT
                    COUNT(*) as total_vectors,
                    COUNT(DISTINCT source_type) as source_types,
                    COUNT(DISTINCT embedding_model) as embedding_models,
                    MIN(created_at) as oldest_vector,
                    MAX(created_at) as newest_vector
                FROM embedding_vectors
                WHERE tenant_id = :tenant_id
            """)

            result = await session.execute(stats_sql, {"tenant_id": tenant_id})
            row = result.fetchone()

            if row:
                return {
                    "total_vectors": row.total_vectors,
                    "source_types": row.source_types,
                    "embedding_models": row.embedding_models,
                    "oldest_vector": row.oldest_vector.isoformat() if row.oldest_vector else None,
                    "newest_vector": row.newest_vector.isoformat() if row.newest_vector else None
                }

        return {
            "total_vectors": 0,
            "source_types": 0,
            "embedding_models": 0,
            "oldest_vector": None,
            "newest_vector": None
        }


# Global vector store instance
_vector_store: Optional[VectorStore] = None


def get_vector_store(dimension: int = 1536) -> VectorStore:
    """Get global vector store instance."""
    global _vector_store

    if _vector_store is None:
        _vector_store = VectorStore(dimension=dimension)

    return _vector_store


# Example embedding function (would integrate with actual embedding service)
async def openai_embedding_function(text: str) -> List[float]:
    """Example embedding function using OpenAI."""
    # In production, this would call OpenAI API or local embedding model
    # For now, return dummy vector
    import random
    return [random.random() for _ in range(1536)]
