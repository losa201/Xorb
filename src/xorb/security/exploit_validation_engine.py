"""
Production-Safe Exploit Validation Engine
Safely validates vulnerabilities and generates proof-of-concepts without causing damage
"""

import asyncio
import json
import logging
import tempfile
import subprocess
import uuid
import hashlib
import base64
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
from pathlib import Path
from enum import Enum
import ipaddress
import socket
import ssl
import aiohttp
import aiofiles

logger = logging.getLogger(__name__)

class ExploitSeverity(Enum):
    INFO = "info"
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

class ExploitType(Enum):
    WEB_APPLICATION = "web_application"
    NETWORK_SERVICE = "network_service"
    PRIVILEGE_ESCALATION = "privilege_escalation"
    REMOTE_CODE_EXECUTION = "remote_code_execution"
    SQL_INJECTION = "sql_injection"
    AUTHENTICATION_BYPASS = "authentication_bypass"
    BUFFER_OVERFLOW = "buffer_overflow"
    CONFIGURATION_ERROR = "configuration_error"

class ValidationResult(Enum):
    CONFIRMED = "confirmed"
    POTENTIAL = "potential"
    FALSE_POSITIVE = "false_positive"
    BLOCKED = "blocked"
    ERROR = "error"

@dataclass
class ExploitPayload:
    """Safe exploit payload for validation"""
    payload_id: str
    name: str
    description: str
    exploit_type: ExploitType
    severity: ExploitSeverity
    target_systems: List[str]
    payload_data: str
    validation_method: str
    safety_level: int  # 1-10, 10 being safest
    mitigation: str
    references: List[str]
    created_at: datetime
    
@dataclass
class ValidationAttempt:
    """Record of exploit validation attempt"""
    attempt_id: str
    payload_id: str
    target: str
    result: ValidationResult
    evidence: List[str]
    response_data: str
    validation_time: datetime
    safety_score: float
    risk_assessment: str
    
@dataclass
class SafetyConstraints:
    """Safety constraints for exploit validation"""
    max_requests_per_target: int = 5
    request_delay_seconds: float = 1.0
    allowed_http_methods: List[str] = None
    forbidden_payloads: List[str] = None
    sandbox_mode: bool = True
    read_only_validation: bool = True
    max_payload_size: int = 1024
    timeout_seconds: int = 10

class ProductionSafeExploitValidator:
    """Production-safe exploit validation engine"""
    
    def __init__(self, safety_constraints: SafetyConstraints = None):
        self.safety_constraints = safety_constraints or SafetyConstraints()
        self.session: Optional[aiohttp.ClientSession] = None
        self.validation_history: List[ValidationAttempt] = []
        self.blocked_targets: Dict[str, datetime] = {}
        self.payload_library: Dict[str, ExploitPayload] = {}
        
        # Initialize safe payload library
        self._initialize_safe_payloads()
        
        # Rate limiting and safety tracking
        self.target_request_counts: Dict[str, int] = {}
        self.last_request_times: Dict[str, datetime] = {}
        
    async def initialize(self) -> bool:
        """Initialize the exploit validation engine"""
        try:
            logger.info("Initializing Production-Safe Exploit Validation Engine...")
            
            # Initialize HTTP session with safety settings
            timeout = aiohttp.ClientTimeout(total=self.safety_constraints.timeout_seconds)
            self.session = aiohttp.ClientSession(timeout=timeout)
            
            # Load additional payloads from configuration
            await self._load_payload_library()
            
            # Initialize safety monitors
            await self._initialize_safety_monitors()
            
            logger.info(f"Exploit validation engine initialized with {len(self.payload_library)} safe payloads")
            return True
            
        except Exception as e:
            logger.error(f"Failed to initialize exploit validation engine: {e}")
            return False
    
    def _initialize_safe_payloads(self):
        """Initialize library of safe exploit payloads"""
        
        # SQL Injection Detection Payloads (Read-only)
        self.payload_library["sqli_union_detect"] = ExploitPayload(
            payload_id="sqli_union_detect",
            name="SQL Injection Union Detection",
            description="Safe detection of SQL injection using UNION statements",
            exploit_type=ExploitType.SQL_INJECTION,
            severity=ExploitSeverity.HIGH,
            target_systems=["web_application"],
            payload_data="' UNION SELECT NULL,NULL,NULL--",
            validation_method="response_analysis",
            safety_level=9,
            mitigation="Use parameterized queries and input validation",
            references=["OWASP-A03", "CWE-89"],
            created_at=datetime.now()
        )
        
        self.payload_library["sqli_error_detect"] = ExploitPayload(
            payload_id="sqli_error_detect",
            name="SQL Injection Error-Based Detection",
            description="Detect SQL injection through database error messages",
            exploit_type=ExploitType.SQL_INJECTION,
            severity=ExploitSeverity.HIGH,
            target_systems=["web_application"],
            payload_data="' AND 1=CONVERT(int,@@version)--",
            validation_method="error_analysis",
            safety_level=9,
            mitigation="Implement proper error handling and input sanitization",
            references=["OWASP-A03", "CWE-89"],
            created_at=datetime.now()
        )
        
        # XSS Detection Payloads (Safe)
        self.payload_library["xss_reflect_detect"] = ExploitPayload(
            payload_id="xss_reflect_detect",
            name="Reflected XSS Detection",
            description="Safe detection of reflected cross-site scripting",
            exploit_type=ExploitType.WEB_APPLICATION,
            severity=ExploitSeverity.MEDIUM,
            target_systems=["web_application"],
            payload_data="<script>console.log('XSS-TEST-" + str(uuid.uuid4())[:8] + "')</script>",
            validation_method="response_content_analysis",
            safety_level=10,
            mitigation="Implement output encoding and Content Security Policy",
            references=["OWASP-A07", "CWE-79"],
            created_at=datetime.now()
        )
        
        # Directory Traversal Detection (Read-only)
        self.payload_library["dir_traversal_detect"] = ExploitPayload(
            payload_id="dir_traversal_detect",
            name="Directory Traversal Detection",
            description="Safe detection of directory traversal vulnerabilities",
            exploit_type=ExploitType.WEB_APPLICATION,
            severity=ExploitSeverity.MEDIUM,
            target_systems=["web_application"],
            payload_data="../../../etc/passwd",
            validation_method="response_content_analysis",
            safety_level=8,
            mitigation="Validate and sanitize file paths, use whitelist approach",
            references=["OWASP-A01", "CWE-22"],
            created_at=datetime.now()
        )
        
        # Authentication Bypass Detection (Safe)
        self.payload_library["auth_bypass_detect"] = ExploitPayload(
            payload_id="auth_bypass_detect",
            name="Authentication Bypass Detection",
            description="Detect authentication bypass vulnerabilities",
            exploit_type=ExploitType.AUTHENTICATION_BYPASS,
            severity=ExploitSeverity.HIGH,
            target_systems=["web_application"],
            payload_data="admin' OR '1'='1",
            validation_method="response_analysis",
            safety_level=9,
            mitigation="Implement proper authentication mechanisms and input validation",
            references=["OWASP-A07", "CWE-287"],
            created_at=datetime.now()
        )
        
        # Command Injection Detection (Safe)
        self.payload_library["cmd_inject_detect"] = ExploitPayload(
            payload_id="cmd_inject_detect",
            name="Command Injection Detection",
            description="Safe detection of command injection vulnerabilities",
            exploit_type=ExploitType.REMOTE_CODE_EXECUTION,
            severity=ExploitSeverity.CRITICAL,
            target_systems=["web_application", "network_service"],
            payload_data="; echo 'CMD-INJECTION-TEST-" + str(uuid.uuid4())[:8] + "'",
            validation_method="response_content_analysis",
            safety_level=7,
            mitigation="Use input validation and avoid system command execution",
            references=["OWASP-A03", "CWE-78"],
            created_at=datetime.now()
        )
        
        # LDAP Injection Detection (Safe)
        self.payload_library["ldap_inject_detect"] = ExploitPayload(
            payload_id="ldap_inject_detect",
            name="LDAP Injection Detection",
            description="Detect LDAP injection vulnerabilities",
            exploit_type=ExploitType.WEB_APPLICATION,
            severity=ExploitSeverity.MEDIUM,
            target_systems=["web_application"],
            payload_data="*)(uid=*",
            validation_method="response_analysis",
            safety_level=9,
            mitigation="Use parameterized LDAP queries and input validation",
            references=["OWASP-A03", "CWE-90"],
            created_at=datetime.now()
        )
        
        # HTTP Header Injection Detection (Safe)
        self.payload_library["header_inject_detect"] = ExploitPayload(
            payload_id="header_inject_detect",
            name="HTTP Header Injection Detection",
            description="Detect HTTP header injection vulnerabilities",
            exploit_type=ExploitType.WEB_APPLICATION,
            severity=ExploitSeverity.MEDIUM,
            target_systems=["web_application"],
            payload_data="\r\nX-Test-Header: injection-test",
            validation_method="response_header_analysis",
            safety_level=9,
            mitigation="Validate and sanitize header values",
            references=["OWASP-A03", "CWE-113"],
            created_at=datetime.now()
        )
        
        # XXE Detection (Safe)
        self.payload_library["xxe_detect"] = ExploitPayload(
            payload_id="xxe_detect",
            name="XML External Entity Detection",
            description="Safe detection of XXE vulnerabilities",
            exploit_type=ExploitType.WEB_APPLICATION,
            severity=ExploitSeverity.HIGH,
            target_systems=["web_application"],
            payload_data='<?xml version="1.0"?><!DOCTYPE test [<!ENTITY xxe "XXE-TEST-DETECTED">]><test>&xxe;</test>',
            validation_method="response_content_analysis",
            safety_level=8,
            mitigation="Disable external entity processing in XML parsers",
            references=["OWASP-A04", "CWE-611"],
            created_at=datetime.now()
        )
        
        logger.info(f"Initialized {len(self.payload_library)} safe exploit payloads")
    
    async def _load_payload_library(self):
        """Load additional payloads from configuration"""
        try:
            # In production, this would load from a configuration file or database
            # For now, we'll just log that the library is ready
            logger.info("Safe payload library loaded successfully")
        except Exception as e:
            logger.error(f"Error loading payload library: {e}")
    
    async def _initialize_safety_monitors(self):
        """Initialize safety monitoring systems"""
        try:
            # Initialize safety constraints
            if not self.safety_constraints.allowed_http_methods:
                self.safety_constraints.allowed_http_methods = ["GET", "POST", "HEAD"]
            
            if not self.safety_constraints.forbidden_payloads:
                self.safety_constraints.forbidden_payloads = [
                    "rm -rf", "DROP TABLE", "DELETE FROM", "format c:",
                    "shutdown", "reboot", "killall", "pkill"
                ]
            
            logger.info("Safety monitoring systems initialized")
        except Exception as e:
            logger.error(f"Error initializing safety monitors: {e}")
    
    async def validate_vulnerability(self, target: str, payload_id: str, 
                                   context: Dict[str, Any] = None) -> ValidationAttempt:
        """Safely validate a vulnerability using specified payload"""
        attempt_id = str(uuid.uuid4())
        start_time = datetime.now()
        
        try:
            # Safety checks
            if not await self._safety_check(target, payload_id):
                return ValidationAttempt(
                    attempt_id=attempt_id,
                    payload_id=payload_id,
                    target=target,
                    result=ValidationResult.BLOCKED,
                    evidence=["Safety check failed"],
                    response_data="",
                    validation_time=start_time,
                    safety_score=0.0,
                    risk_assessment="High risk - validation blocked"
                )
            
            # Get payload
            payload = self.payload_library.get(payload_id)
            if not payload:
                raise ValueError(f"Payload {payload_id} not found")
            
            # Rate limiting
            await self._enforce_rate_limiting(target)
            
            # Execute validation based on payload type
            if payload.exploit_type == ExploitType.SQL_INJECTION:
                result = await self._validate_sql_injection(target, payload, context)
            elif payload.exploit_type == ExploitType.WEB_APPLICATION:
                result = await self._validate_web_vulnerability(target, payload, context)
            elif payload.exploit_type == ExploitType.AUTHENTICATION_BYPASS:
                result = await self._validate_auth_bypass(target, payload, context)
            else:
                result = await self._validate_generic_vulnerability(target, payload, context)
            
            # Create validation attempt record
            attempt = ValidationAttempt(
                attempt_id=attempt_id,
                payload_id=payload_id,
                target=target,
                result=result["result"],
                evidence=result["evidence"],
                response_data=result.get("response_data", ""),
                validation_time=start_time,
                safety_score=result.get("safety_score", payload.safety_level / 10.0),
                risk_assessment=result.get("risk_assessment", "Safe validation")
            )
            
            # Store attempt
            self.validation_history.append(attempt)
            
            logger.info(f"Validation completed: {payload_id} against {target} - {result['result']}")
            return attempt
            
        except Exception as e:
            logger.error(f"Validation failed: {e}")
            return ValidationAttempt(
                attempt_id=attempt_id,
                payload_id=payload_id,
                target=target,
                result=ValidationResult.ERROR,
                evidence=[str(e)],
                response_data="",
                validation_time=start_time,
                safety_score=0.0,
                risk_assessment=f"Error during validation: {e}"
            )
    
    async def _safety_check(self, target: str, payload_id: str) -> bool:
        """Perform comprehensive safety check before validation"""
        try:
            # Check if target is blocked
            if target in self.blocked_targets:
                block_time = self.blocked_targets[target]
                if datetime.now() - block_time < timedelta(hours=1):
                    logger.warning(f"Target {target} is temporarily blocked")
                    return False
            
            # Check payload safety level
            payload = self.payload_library.get(payload_id)
            if not payload or payload.safety_level < 7:
                logger.warning(f"Payload {payload_id} safety level too low")
                return False
            
            # Check forbidden payload patterns
            if payload and any(forbidden in payload.payload_data.lower() 
                             for forbidden in self.safety_constraints.forbidden_payloads):
                logger.warning(f"Payload {payload_id} contains forbidden patterns")
                return False
            
            # Validate target format
            if not await self._validate_target_format(target):
                logger.warning(f"Invalid target format: {target}")
                return False
            
            # Check rate limits
            current_count = self.target_request_counts.get(target, 0)
            if current_count >= self.safety_constraints.max_requests_per_target:
                logger.warning(f"Rate limit exceeded for target {target}")
                return False
            
            return True
            
        except Exception as e:
            logger.error(f"Safety check failed: {e}")
            return False
    
    async def _validate_target_format(self, target: str) -> bool:
        """Validate target URL/address format"""
        try:
            # Basic URL validation
            if target.startswith(('http://', 'https://')):
                # URL format validation
                if len(target) > 200:  # Reasonable URL length limit
                    return False
                
                # Check for dangerous protocols
                dangerous_protocols = ['file://', 'ftp://', 'ldap://']
                if any(target.lower().startswith(proto) for proto in dangerous_protocols):
                    return False
                
                return True
            
            # IP address validation
            try:
                ipaddress.ip_address(target)
                return True
            except ValueError:
                pass
            
            # Domain name validation (basic)
            if '.' in target and len(target) <= 253:
                return True
            
            return False
            
        except Exception:
            return False
    
    async def _enforce_rate_limiting(self, target: str):
        """Enforce rate limiting for target"""
        current_time = datetime.now()
        
        # Check time since last request
        if target in self.last_request_times:
            time_diff = (current_time - self.last_request_times[target]).total_seconds()
            if time_diff < self.safety_constraints.request_delay_seconds:
                sleep_time = self.safety_constraints.request_delay_seconds - time_diff
                await asyncio.sleep(sleep_time)
        
        # Update counters
        self.target_request_counts[target] = self.target_request_counts.get(target, 0) + 1
        self.last_request_times[target] = current_time
    
    async def _validate_sql_injection(self, target: str, payload: ExploitPayload, 
                                    context: Dict[str, Any]) -> Dict[str, Any]:
        """Safely validate SQL injection vulnerability"""
        try:
            evidence = []
            response_data = ""
            
            # Construct safe test URL
            if '?' not in target:
                test_url = f"{target}?id={payload.payload_data}"
            else:
                test_url = f"{target}&test={payload.payload_data}"
            
            # Make safe HTTP request
            async with self.session.get(test_url) as response:
                response_data = await response.text()
                status_code = response.status
                headers = dict(response.headers)
            
            # Analyze response for SQL injection indicators
            sql_error_patterns = [
                "SQL syntax", "mysql_fetch_array", "ORA-", "Microsoft OLE DB",
                "PostgreSQL", "Warning: pg_", "valid MySQL result", "SQLite error",
                "Syntax error", "database error", "SQL command not properly ended"
            ]
            
            for pattern in sql_error_patterns:
                if pattern.lower() in response_data.lower():
                    evidence.append(f"SQL error pattern detected: {pattern}")
            
            # Check for UNION SELECT response patterns
            if "union" in payload.payload_data.lower():
                if len(response_data) != len(await self._get_baseline_response(target)):
                    evidence.append("Response length differs from baseline (potential UNION injection)")
            
            # Determine result
            if evidence:
                result = ValidationResult.CONFIRMED
                risk_assessment = "SQL injection vulnerability confirmed"
            else:
                result = ValidationResult.FALSE_POSITIVE
                risk_assessment = "No SQL injection indicators found"
            
            return {
                "result": result,
                "evidence": evidence,
                "response_data": response_data[:500],  # Limit response data
                "safety_score": 0.9,
                "risk_assessment": risk_assessment
            }
            
        except Exception as e:
            logger.error(f"SQL injection validation failed: {e}")
            return {
                "result": ValidationResult.ERROR,
                "evidence": [str(e)],
                "response_data": "",
                "safety_score": 0.0,
                "risk_assessment": f"Validation error: {e}"
            }
    
    async def _validate_web_vulnerability(self, target: str, payload: ExploitPayload, 
                                        context: Dict[str, Any]) -> Dict[str, Any]:
        """Safely validate web application vulnerability"""
        try:
            evidence = []
            response_data = ""
            
            if payload.payload_id == "xss_reflect_detect":
                # XSS validation
                test_url = f"{target}?search={payload.payload_data}"
                
                async with self.session.get(test_url) as response:
                    response_data = await response.text()
                    
                # Check if payload is reflected in response
                payload_marker = payload.payload_data
                if payload_marker in response_data:
                    evidence.append("XSS payload reflected in response")
                    evidence.append("Script tags not properly encoded")
                
            elif payload.payload_id == "dir_traversal_detect":
                # Directory traversal validation
                test_url = f"{target}?file={payload.payload_data}"
                
                async with self.session.get(test_url) as response:
                    response_data = await response.text()
                    
                # Check for common file content patterns
                traversal_indicators = [
                    "root:x:", "bin/bash", "etc/passwd", "Windows\\System32",
                    "[boot loader]", "# User Database"
                ]
                
                for indicator in traversal_indicators:
                    if indicator in response_data:
                        evidence.append(f"File content indicator found: {indicator}")
            
            elif payload.payload_id == "xxe_detect":
                # XXE validation
                headers = {"Content-Type": "application/xml"}
                
                async with self.session.post(target, data=payload.payload_data, headers=headers) as response:
                    response_data = await response.text()
                    
                # Check for XXE entity resolution
                if "XXE-TEST-DETECTED" in response_data:
                    evidence.append("XXE entity resolved in response")
            
            # Determine result
            if evidence:
                result = ValidationResult.CONFIRMED
                risk_assessment = f"{payload.exploit_type.value} vulnerability confirmed"
            else:
                result = ValidationResult.FALSE_POSITIVE
                risk_assessment = "No vulnerability indicators found"
            
            return {
                "result": result,
                "evidence": evidence,
                "response_data": response_data[:500],
                "safety_score": 0.9,
                "risk_assessment": risk_assessment
            }
            
        except Exception as e:
            logger.error(f"Web vulnerability validation failed: {e}")
            return {
                "result": ValidationResult.ERROR,
                "evidence": [str(e)],
                "response_data": "",
                "safety_score": 0.0,
                "risk_assessment": f"Validation error: {e}"
            }
    
    async def _validate_auth_bypass(self, target: str, payload: ExploitPayload, 
                                   context: Dict[str, Any]) -> Dict[str, Any]:
        """Safely validate authentication bypass vulnerability"""
        try:
            evidence = []
            response_data = ""
            
            # Test authentication bypass
            if context and "login_url" in context:
                login_url = context["login_url"]
                login_data = {
                    "username": payload.payload_data,
                    "password": "test"
                }
                
                async with self.session.post(login_url, data=login_data) as response:
                    response_data = await response.text()
                    status_code = response.status
                    headers = dict(response.headers)
                
                # Check for successful authentication indicators
                success_indicators = [
                    "welcome", "dashboard", "logout", "profile",
                    "authentication successful", "login successful"
                ]
                
                for indicator in success_indicators:
                    if indicator.lower() in response_data.lower():
                        evidence.append(f"Authentication success indicator: {indicator}")
                
                # Check for redirect patterns
                if status_code in [301, 302, 303, 307, 308]:
                    if "location" in headers:
                        location = headers["location"]
                        if any(path in location.lower() for path in ["/dashboard", "/home", "/admin"]):
                            evidence.append(f"Redirect to protected area: {location}")
            
            # Determine result
            if evidence:
                result = ValidationResult.CONFIRMED
                risk_assessment = "Authentication bypass vulnerability confirmed"
            else:
                result = ValidationResult.FALSE_POSITIVE
                risk_assessment = "No authentication bypass indicators found"
            
            return {
                "result": result,
                "evidence": evidence,
                "response_data": response_data[:500],
                "safety_score": 0.8,
                "risk_assessment": risk_assessment
            }
            
        except Exception as e:
            logger.error(f"Authentication bypass validation failed: {e}")
            return {
                "result": ValidationResult.ERROR,
                "evidence": [str(e)],
                "response_data": "",
                "safety_score": 0.0,
                "risk_assessment": f"Validation error: {e}"
            }
    
    async def _validate_generic_vulnerability(self, target: str, payload: ExploitPayload, 
                                            context: Dict[str, Any]) -> Dict[str, Any]:
        """Generic vulnerability validation for unsupported types"""
        try:
            evidence = []
            response_data = ""
            
            # Basic HTTP request with payload
            test_url = f"{target}?test={payload.payload_data}"
            
            async with self.session.get(test_url) as response:
                response_data = await response.text()
                status_code = response.status
            
            # Basic analysis
            if status_code >= 500:
                evidence.append(f"Server error response: {status_code}")
            
            if len(response_data) > 10000:
                evidence.append("Unusually large response (potential information disclosure)")
            
            # Generic error patterns
            error_patterns = ["error", "exception", "warning", "failed", "denied"]
            for pattern in error_patterns:
                if pattern in response_data.lower():
                    evidence.append(f"Error pattern detected: {pattern}")
                    break
            
            # Determine result
            if evidence:
                result = ValidationResult.POTENTIAL
                risk_assessment = "Potential vulnerability indicators found"
            else:
                result = ValidationResult.FALSE_POSITIVE
                risk_assessment = "No clear vulnerability indicators"
            
            return {
                "result": result,
                "evidence": evidence,
                "response_data": response_data[:500],
                "safety_score": 0.7,
                "risk_assessment": risk_assessment
            }
            
        except Exception as e:
            logger.error(f"Generic vulnerability validation failed: {e}")
            return {
                "result": ValidationResult.ERROR,
                "evidence": [str(e)],
                "response_data": "",
                "safety_score": 0.0,
                "risk_assessment": f"Validation error: {e}"
            }
    
    async def _get_baseline_response(self, target: str) -> str:
        """Get baseline response from target for comparison"""
        try:
            async with self.session.get(target) as response:
                return await response.text()
        except Exception:
            return ""
    
    async def batch_validate_vulnerabilities(self, target: str, payload_ids: List[str], 
                                           context: Dict[str, Any] = None) -> List[ValidationAttempt]:
        """Safely validate multiple vulnerabilities in batch"""
        results = []
        
        for payload_id in payload_ids:
            try:
                # Safety delay between requests
                if results:  # Not the first request
                    await asyncio.sleep(self.safety_constraints.request_delay_seconds)
                
                attempt = await self.validate_vulnerability(target, payload_id, context)
                results.append(attempt)
                
                # Stop batch if we hit safety limits
                if len(results) >= self.safety_constraints.max_requests_per_target:
                    logger.warning(f"Batch validation stopped due to safety limits")
                    break
                    
            except Exception as e:
                logger.error(f"Batch validation error for {payload_id}: {e}")
        
        return results
    
    async def generate_proof_of_concept(self, validation_attempt: ValidationAttempt) -> Dict[str, Any]:
        """Generate safe proof-of-concept for confirmed vulnerabilities"""
        try:
            if validation_attempt.result != ValidationResult.CONFIRMED:
                return {"error": "Can only generate PoC for confirmed vulnerabilities"}
            
            payload = self.payload_library.get(validation_attempt.payload_id)
            if not payload:
                return {"error": "Payload not found"}
            
            poc = {
                "vulnerability_id": validation_attempt.attempt_id,
                "payload_id": validation_attempt.payload_id,
                "vulnerability_type": payload.exploit_type.value,
                "severity": payload.severity.value,
                "target": validation_attempt.target,
                "proof_of_concept": {
                    "description": payload.description,
                    "steps": await self._generate_poc_steps(payload, validation_attempt),
                    "evidence": validation_attempt.evidence,
                    "mitigation": payload.mitigation,
                    "references": payload.references
                },
                "safety_notice": "This PoC is for educational and authorized testing purposes only",
                "generated_at": datetime.now().isoformat()
            }
            
            return poc
            
        except Exception as e:
            logger.error(f"PoC generation failed: {e}")
            return {"error": str(e)}
    
    async def _generate_poc_steps(self, payload: ExploitPayload, 
                                validation_attempt: ValidationAttempt) -> List[str]:
        """Generate step-by-step PoC instructions"""
        steps = []
        
        if payload.exploit_type == ExploitType.SQL_INJECTION:
            steps = [
                f"1. Navigate to target URL: {validation_attempt.target}",
                f"2. Append SQL injection payload to a parameter: {payload.payload_data}",
                "3. Observe server response for SQL error messages",
                "4. Evidence found: " + ", ".join(validation_attempt.evidence),
                "5. Mitigation: " + payload.mitigation
            ]
        elif payload.exploit_type == ExploitType.WEB_APPLICATION:
            if "xss" in payload.payload_id:
                steps = [
                    f"1. Navigate to target URL: {validation_attempt.target}",
                    f"2. Input XSS payload into a form field or URL parameter: {payload.payload_data}",
                    "3. Submit the form or navigate to the modified URL",
                    "4. Check if the script payload is reflected in the response",
                    "5. Evidence found: " + ", ".join(validation_attempt.evidence),
                    "6. Mitigation: " + payload.mitigation
                ]
            elif "traversal" in payload.payload_id:
                steps = [
                    f"1. Navigate to target URL: {validation_attempt.target}",
                    f"2. Modify file parameter with traversal payload: {payload.payload_data}",
                    "3. Attempt to access system files",
                    "4. Check response for system file contents",
                    "5. Evidence found: " + ", ".join(validation_attempt.evidence),
                    "6. Mitigation: " + payload.mitigation
                ]
        else:
            steps = [
                f"1. Target: {validation_attempt.target}",
                f"2. Payload: {payload.payload_data}",
                f"3. Method: {payload.validation_method}",
                "4. Evidence: " + ", ".join(validation_attempt.evidence),
                "5. Mitigation: " + payload.mitigation
            ]
        
        return steps
    
    async def get_validation_report(self, target: str = None) -> Dict[str, Any]:
        """Generate comprehensive validation report"""
        try:
            attempts = self.validation_history
            if target:
                attempts = [a for a in attempts if a.target == target]
            
            if not attempts:
                return {"message": "No validation attempts found"}
            
            # Calculate statistics
            total_attempts = len(attempts)
            confirmed_vulns = len([a for a in attempts if a.result == ValidationResult.CONFIRMED])
            potential_vulns = len([a for a in attempts if a.result == ValidationResult.POTENTIAL])
            false_positives = len([a for a in attempts if a.result == ValidationResult.FALSE_POSITIVE])
            blocked_attempts = len([a for a in attempts if a.result == ValidationResult.BLOCKED])
            errors = len([a for a in attempts if a.result == ValidationResult.ERROR])
            
            # Group by vulnerability type
            vuln_types = {}
            for attempt in attempts:
                payload = self.payload_library.get(attempt.payload_id)
                if payload:
                    vuln_type = payload.exploit_type.value
                    if vuln_type not in vuln_types:
                        vuln_types[vuln_type] = {"confirmed": 0, "potential": 0, "false_positive": 0}
                    
                    if attempt.result == ValidationResult.CONFIRMED:
                        vuln_types[vuln_type]["confirmed"] += 1
                    elif attempt.result == ValidationResult.POTENTIAL:
                        vuln_types[vuln_type]["potential"] += 1
                    else:
                        vuln_types[vuln_type]["false_positive"] += 1
            
            # Calculate average safety score
            safety_scores = [a.safety_score for a in attempts if a.safety_score > 0]
            avg_safety_score = sum(safety_scores) / len(safety_scores) if safety_scores else 0.0
            
            return {
                "validation_summary": {
                    "total_attempts": total_attempts,
                    "confirmed_vulnerabilities": confirmed_vulns,
                    "potential_vulnerabilities": potential_vulns,
                    "false_positives": false_positives,
                    "blocked_attempts": blocked_attempts,
                    "validation_errors": errors,
                    "success_rate": (confirmed_vulns + potential_vulns) / total_attempts if total_attempts > 0 else 0.0,
                    "average_safety_score": round(avg_safety_score, 2)
                },
                "vulnerability_breakdown": vuln_types,
                "targets_tested": len(set(a.target for a in attempts)),
                "payloads_used": len(set(a.payload_id for a in attempts)),
                "validation_period": {
                    "start": min(a.validation_time for a in attempts).isoformat(),
                    "end": max(a.validation_time for a in attempts).isoformat()
                },
                "safety_compliance": {
                    "all_attempts_safe": all(a.safety_score >= 0.7 for a in attempts),
                    "no_dangerous_payloads": not any(self.payload_library.get(a.payload_id, ExploitPayload("", "", "", ExploitType.WEB_APPLICATION, ExploitSeverity.LOW, [], "", "", 10, "", [], datetime.now())).safety_level < 7 for a in attempts),
                    "rate_limits_respected": True  # This would be calculated based on actual timing
                }
            }
            
        except Exception as e:
            logger.error(f"Report generation failed: {e}")
            return {"error": str(e)}
    
    async def shutdown(self):
        """Shutdown the exploit validation engine"""
        if self.session:
            await self.session.close()
        
        logger.info("Production-Safe Exploit Validation Engine shutdown complete")

# Global instance management
_exploit_validator: Optional[ProductionSafeExploitValidator] = None

async def get_exploit_validator() -> ProductionSafeExploitValidator:
    """Get global exploit validator instance"""
    global _exploit_validator
    
    if _exploit_validator is None:
        _exploit_validator = ProductionSafeExploitValidator()
        await _exploit_validator.initialize()
    
    return _exploit_validator