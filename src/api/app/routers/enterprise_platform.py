"""
Enterprise Platform Management Router
Advanced capabilities for enterprise-grade operations
"""

import asyncio
from datetime import datetime
from typing import Dict, List, Optional, Any
from fastapi import APIRouter, Depends, HTTPException, BackgroundTasks
from pydantic import BaseModel

from ..enhanced_container import get_container
from ..auth.dependencies import get_current_user, require_auth
from ..auth.models import UserClaims
from ..infrastructure.observability import add_trace_context

router = APIRouter(
    prefix="/api/v1/enterprise",
    tags=["Enterprise Platform Management"],
    dependencies=[Depends(get_current_user)]
)

# Request/Response Models
class DatabaseOptimizationRequest(BaseModel):
    """Database optimization configuration"""
    enable_query_optimization: bool = True
    analyze_slow_queries: bool = True
    update_connection_pool: bool = False
    pool_size: Optional[int] = None
    max_overflow: Optional[int] = None

class MLTrainingRequest(BaseModel):
    """ML model training request"""
    model_name: str
    algorithm: str = "random_forest"
    training_data_source: str
    hyperparameters: Dict[str, Any] = {}
    auto_deploy: bool = False

class ServiceDiscoveryQuery(BaseModel):
    """Service discovery query parameters"""
    service_name: Optional[str] = None
    environment: Optional[str] = None
    capabilities: List[str] = []
    health_status: Optional[str] = None

class PlatformHealthResponse(BaseModel):
    """Platform health status response"""
    status: str
    timestamp: datetime
    components: Dict[str, Any]
    performance_metrics: Dict[str, Any]
    service_topology: Dict[str, Any]

@router.get("/health", 
           summary="Get comprehensive platform health",
           response_model=PlatformHealthResponse)
async def get_platform_health(current_user: UserClaims = Depends(get_current_user)):
    """
    Get comprehensive health status of the entire XORB Enterprise platform
    including all advanced components and performance metrics.
    """
    try:
        add_trace_context(operation="platform_health_check", user_id=str(current_user.user_id))
        
        container = get_container()
        
        # Get container health
        health_status = await container.get_health_status()
        
        # Get database performance metrics
        db_metrics = {}
        if container.database_manager:
            db_metrics = await container.database_manager.get_performance_metrics()
        
        # Get service topology
        service_topology = {}
        if container.service_discovery:
            service_topology = await container.service_discovery.get_service_topology()
        
        # Get ML pipeline status
        ml_status = {}
        if container.ml_pipeline:
            ml_status = await container.ml_pipeline.get_model_performance()
        
        return PlatformHealthResponse(
            status=health_status.get("status", "unknown"),
            timestamp=datetime.now(),
            components=health_status.get("components", {}),
            performance_metrics={
                "database": db_metrics,
                "ml_pipeline": ml_status,
                "service_count": health_status.get("service_count", 0),
                "initialization_time": health_status.get("initialization_time", 0)
            },
            service_topology=service_topology
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Health check failed: {str(e)}")

@router.post("/database/optimize",
            summary="Optimize database performance",
            dependencies=[Depends(require_auth)])
async def optimize_database(
    request: DatabaseOptimizationRequest,
    background_tasks: BackgroundTasks,
    current_user: UserClaims = Depends(require_auth)
):
    """
    Perform advanced database optimization including query analysis,
    connection pool tuning, and performance monitoring setup.
    """
    try:
        add_trace_context(
            operation="database_optimization", 
            user_id=str(current_user.user_id),
            optimization_type="manual"
        )
        
        container = get_container()
        
        if not container.database_manager:
            raise HTTPException(
                status_code=503, 
                detail="Advanced database manager not available"
            )
        
        results = {
            "optimization_started": datetime.now(),
            "tasks": []
        }
        
        # Query optimization analysis
        if request.enable_query_optimization:
            optimization_result = await container.database_manager.optimize_queries()
            results["query_optimization"] = optimization_result
            results["tasks"].append("query_optimization_completed")
        
        # Connection pool analysis
        if request.analyze_slow_queries:
            pool_status = await container.database_manager.get_connection_pool_status()
            results["connection_pool_status"] = pool_status
            results["tasks"].append("connection_pool_analyzed")
        
        # Background optimization task
        if request.update_connection_pool:
            async def background_optimization():
                try:
                    # Perform background optimization
                    await asyncio.sleep(1)  # Simulate optimization work
                    # In real implementation, would update pool configuration
                    pass
                except Exception as e:
                    logger.error(f"Background optimization failed: {e}")
            
            background_tasks.add_task(background_optimization)
            results["tasks"].append("background_optimization_scheduled")
        
        return {
            "success": True,
            "message": "Database optimization completed",
            "results": results
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=500, 
            detail=f"Database optimization failed: {str(e)}"
        )

@router.post("/ml/train-model",
            summary="Train new ML model",
            dependencies=[Depends(require_auth)])
async def train_ml_model(
    request: MLTrainingRequest,
    background_tasks: BackgroundTasks,
    current_user: UserClaims = Depends(require_auth)
):
    """
    Train a new machine learning model for threat detection or anomaly analysis.
    Supports multiple algorithms and automatic deployment.
    """
    try:
        add_trace_context(
            operation="ml_model_training",
            user_id=str(current_user.user_id),
            model_name=request.model_name,
            algorithm=request.algorithm
        )
        
        container = get_container()
        
        if not container.ml_pipeline:
            raise HTTPException(
                status_code=503,
                detail="ML pipeline not available"
            )
        
        # Background training task
        async def background_training():
            try:
                # Generate sample training data (in production, load from actual source)
                training_data = [
                    {
                        "feature_1": i * 0.1,
                        "feature_2": i * 0.2,
                        "feature_3": i * 0.05,
                        "is_threat": i % 10 == 0  # 10% threats
                    }
                    for i in range(1000)
                ]
                
                # Train the model
                if request.model_name == "threat_classifier":
                    metadata = await container.ml_pipeline.train_threat_classification_model(
                        training_data=training_data,
                        model_name=request.model_name,
                        algorithm=request.algorithm
                    )
                elif request.model_name == "anomaly_detector":
                    # Use only normal data for anomaly detection
                    normal_data = [d for d in training_data if not d["is_threat"]]
                    metadata = await container.ml_pipeline.train_anomaly_detection_model(
                        normal_data=normal_data,
                        model_name=request.model_name
                    )
                else:
                    raise ValueError(f"Unsupported model type: {request.model_name}")
                
                # Auto-deploy if requested
                if request.auto_deploy:
                    await container.ml_pipeline.deploy_model(
                        model_id=metadata.model_id,
                        deployment_config={}
                    )
                
            except Exception as e:
                logger.error(f"ML model training failed: {e}")
        
        background_tasks.add_task(background_training)
        
        return {
            "success": True,
            "message": f"ML model training started: {request.model_name}",
            "model_name": request.model_name,
            "algorithm": request.algorithm,
            "training_started": datetime.now(),
            "auto_deploy": request.auto_deploy
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"ML model training failed: {str(e)}"
        )

@router.get("/ml/models",
           summary="List ML models")
async def list_ml_models(current_user: UserClaims = Depends(get_current_user)):
    """Get list of all ML models and their performance metrics."""
    try:
        container = get_container()
        
        if not container.ml_pipeline:
            return {"models": [], "message": "ML pipeline not available"}
        
        # Get model performance
        model_performance = await container.ml_pipeline.get_model_performance()
        
        models = []
        for model_id, performance in model_performance.items():
            models.append({
                "model_id": model_id,
                "accuracy": performance.get("accuracy", 0.0),
                "precision": performance.get("precision", 0.0),
                "recall": performance.get("recall", 0.0),
                "f1_score": performance.get("f1_score", 0.0),
                "last_updated": performance.get("last_updated")
            })
        
        return {
            "models": models,
            "total_count": len(models)
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to list models: {str(e)}")

@router.post("/ml/predict",
            summary="Make ML prediction")
async def make_ml_prediction(
    input_data: Dict[str, Any],
    model_name: str = "threat_classifier",
    current_user: UserClaims = Depends(get_current_user)
):
    """Make a prediction using trained ML models."""
    try:
        add_trace_context(
            operation="ml_prediction",
            user_id=str(current_user.user_id),
            model_name=model_name
        )
        
        container = get_container()
        
        if not container.ml_pipeline:
            raise HTTPException(
                status_code=503,
                detail="ML pipeline not available"
            )
        
        # Make prediction
        if model_name == "threat_classifier":
            result = await container.ml_pipeline.predict_threat(
                input_data=input_data,
                model_name=model_name,
                explain=True
            )
        elif model_name == "anomaly_detector":
            result = await container.ml_pipeline.detect_anomaly(
                input_data=input_data,
                model_name=model_name
            )
        else:
            raise HTTPException(
                status_code=400,
                detail=f"Unsupported model: {model_name}"
            )
        
        return {
            "prediction": result.prediction,
            "confidence": result.confidence,
            "probability_distribution": result.probability_distribution,
            "feature_contributions": result.feature_contributions,
            "model_version": result.model_version,
            "processing_time_ms": result.processing_time_ms
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Prediction failed: {str(e)}")

@router.post("/services/discover",
            summary="Discover services")
async def discover_services(
    query: ServiceDiscoveryQuery,
    current_user: UserClaims = Depends(get_current_user)
):
    """Discover services in the platform using advanced service discovery."""
    try:
        container = get_container()
        
        if not container.service_discovery:
            return {"services": [], "message": "Service discovery not available"}
        
        # Convert capabilities to enum values
        from ..infrastructure.enterprise_service_discovery import ServiceCapability, ServiceStatus
        
        capabilities = []
        for cap_str in query.capabilities:
            try:
                capabilities.append(ServiceCapability(cap_str))
            except ValueError:
                pass  # Skip invalid capabilities
        
        health_status = None
        if query.health_status:
            try:
                health_status = ServiceStatus(query.health_status)
            except ValueError:
                pass
        
        # Discover services
        services = await container.service_discovery.discover_services(
            service_name=query.service_name,
            capabilities=capabilities,
            environment=query.environment,
            health_status=health_status
        )
        
        # Convert to response format
        service_list = []
        for service in services:
            service_list.append({
                "service_id": service.service_id,
                "service_name": service.service_name,
                "version": service.version,
                "health_status": service.health_status.value,
                "endpoints": [
                    {
                        "protocol": ep.protocol,
                        "host": ep.host,
                        "port": ep.port,
                        "url": ep.url
                    }
                    for ep in service.endpoints
                ],
                "capabilities": [cap.value for cap in service.capabilities],
                "environment": service.environment,
                "last_heartbeat": service.last_heartbeat.isoformat()
            })
        
        return {
            "services": service_list,
            "total_count": len(service_list),
            "query": query.dict()
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Service discovery failed: {str(e)}")

@router.get("/services/topology",
           summary="Get service topology")
async def get_service_topology(current_user: UserClaims = Depends(get_current_user)):
    """Get the complete service topology and dependency graph."""
    try:
        container = get_container()
        
        if not container.service_discovery:
            return {"topology": {}, "message": "Service discovery not available"}
        
        topology = await container.service_discovery.get_service_topology()
        
        return {
            "topology": topology,
            "generated_at": datetime.now().isoformat()
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get topology: {str(e)}")

@router.post("/database/backup",
            summary="Create database backup",
            dependencies=[Depends(require_auth)])
async def create_database_backup(
    background_tasks: BackgroundTasks,
    current_user: UserClaims = Depends(require_auth)
):
    """Create a compressed and encrypted database backup."""
    try:
        add_trace_context(
            operation="database_backup",
            user_id=str(current_user.user_id)
        )
        
        container = get_container()
        
        if not container.database_manager:
            raise HTTPException(
                status_code=503,
                detail="Advanced database manager not available"
            )
        
        # Background backup task
        async def background_backup():
            try:
                backup_result = await container.database_manager.backup_database()
                # In production, would store backup metadata and notify completion
                logger.info(f"Database backup completed: {backup_result}")
            except Exception as e:
                logger.error(f"Database backup failed: {e}")
        
        background_tasks.add_task(background_backup)
        
        return {
            "success": True,
            "message": "Database backup started",
            "backup_initiated": datetime.now().isoformat()
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Backup initiation failed: {str(e)}")

import logging
logger = logging.getLogger(__name__)