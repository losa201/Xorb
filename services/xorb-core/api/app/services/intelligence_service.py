"""Real Intelligence Service implementation with AI integration."""
import asyncio
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from uuid import UUID, uuid4

from sqlalchemy import select, update, and_
from sqlalchemy.ext.asyncio import AsyncSession

from ..domain.tenant_entities import Finding
from ..infrastructure.database import get_async_session
from ..infrastructure.vector_store import get_vector_store

logger = logging.getLogger(__name__)


def _get_decision_types():
    """Get decision types at runtime to avoid circular imports."""
    from ..routers.intelligence import DecisionType, ModelType
    return DecisionType, ModelType


def _get_response_type():
    """Get response types at runtime."""
    from ..routers.intelligence import DecisionResponse
    return DecisionResponse


def _get_context_type():
    """Get context types at runtime."""
    from ..routers.intelligence import DecisionContext
    return DecisionContext


class IntelligenceService:
    """Real Intelligence Service with AI decision making."""
    
    def __init__(self):
        self.vector_store = None
        self._model_cache = {}
        
    async def initialize(self):
        """Initialize the intelligence service."""
        try:
            self.vector_store = await get_vector_store()
            logger.info("Intelligence service initialized")
        except Exception as e:
            logger.warning(f"Vector store initialization failed: {e}")
    
    async def process_decision_request(
        self, 
        request: Any, 
        tenant_id: UUID
    ) -> Any:
        """Process an AI decision request with real analysis."""
        decision_id = str(uuid4())
        start_time = datetime.utcnow()
        
        try:
            # Select best model for decision type
            model = await self._select_optimal_model(
                request.decision_type, 
                request.model_preferences
            )
            
            # Enhance context with tenant-specific data
            enhanced_context = await self._enhance_decision_context(
                request.context, 
                tenant_id
            )
            
            # Process decision using selected approach
            decision_result = await self._make_intelligent_decision(
                request.decision_type,
                enhanced_context,
                model
            )
            
            # Calculate processing metrics
            processing_time = (datetime.utcnow() - start_time).total_seconds() * 1000
            
            # Create structured response
            DecisionResponse = _get_response_type()
            response = DecisionResponse(
                decision_id=decision_id,
                decision_type=request.decision_type,
                recommendation=decision_result["recommendation"],
                alternatives=decision_result.get("alternatives", []),
                confidence_score=decision_result["confidence"],
                reasoning=decision_result.get("reasoning", []),
                supporting_evidence=decision_result.get("evidence", {}),
                model_used=model,
                processing_time_ms=int(processing_time),
                timestamp=start_time,
                expires_at=start_time + timedelta(hours=24) if decision_result.get("expires") else None
            )
            
            # Store decision for learning
            await self._store_decision(response, tenant_id)
            
            return response
            
        except Exception as e:
            logger.error(f"Decision processing failed: {e}")
            # Return fallback decision
            return await self._create_fallback_decision(request, decision_id, start_time)
    
    async def _select_optimal_model(
        self, 
        decision_type: Any,
        preferences: List[Any]
    ) -> Any:
        """Select optimal model based on decision type and performance."""
        
        # Get types at runtime
        DecisionType, ModelType = _get_decision_types()
        
        # Model capability matrix
        model_capabilities = {
            ModelType.QWEN3_ORCHESTRATOR: {
                DecisionType.ORCHESTRATION_OPTIMIZATION: 0.95,
                DecisionType.RESOURCE_ALLOCATION: 0.90,
                DecisionType.TASK_PRIORITIZATION: 0.88,
                DecisionType.AGENT_ASSIGNMENT: 0.85
            },
            ModelType.CLAUDE_AGENT: {
                DecisionType.THREAT_CLASSIFICATION: 0.92,
                DecisionType.RISK_ASSESSMENT: 0.89,
                DecisionType.SECURITY_POSTURE: 0.87,
                DecisionType.RESPONSE_STRATEGY: 0.85
            },
            ModelType.THREAT_CLASSIFIER: {
                DecisionType.THREAT_CLASSIFICATION: 0.96,
                DecisionType.RISK_ASSESSMENT: 0.88,
                DecisionType.SECURITY_POSTURE: 0.82
            }
        }
        
        # Find best model for decision type
        best_model = ModelType.QWEN3_ORCHESTRATOR
        best_score = 0.0
        
        for model, capabilities in model_capabilities.items():
            score = capabilities.get(decision_type, 0.0)
            
            # Boost score if model is preferred
            if model in preferences:
                score += 0.1
                
            if score > best_score:
                best_score = score
                best_model = model
        
        return best_model
    
    async def _enhance_decision_context(
        self, 
        context: Any, 
        tenant_id: UUID
    ) -> Any:
        """Enhance context with tenant-specific intelligence data."""
        
        try:
            # Get recent findings for context
            async with get_async_session() as session:
                result = await session.execute(
                    select(Finding)
                    .where(Finding.tenant_id == tenant_id)
                    .order_by(Finding.created_at.desc())
                    .limit(10)
                )
                recent_findings = result.scalars().all()
            
            # Add threat intelligence context
            threat_context = []
            for finding in recent_findings:
                threat_context.append({
                    "severity": finding.severity,
                    "category": finding.category,
                    "tags": finding.tags or [],
                    "created_at": finding.created_at.isoformat(),
                    "attack_techniques": finding.attack_techniques or []
                })
            
            # Enhance available data
            enhanced_data = context.available_data.copy()
            enhanced_data["recent_threats"] = threat_context
            enhanced_data["tenant_risk_score"] = await self._calculate_tenant_risk_score(tenant_id)
            
            # Add vector similarity search if available
            if self.vector_store and context.scenario:
                similar_cases = await self._find_similar_scenarios(context.scenario, tenant_id)
                enhanced_data["similar_cases"] = similar_cases
            
            # Return enhanced context
            DecisionContext = _get_context_type()
            return DecisionContext(
                scenario=context.scenario,
                available_data=enhanced_data,
                constraints=context.constraints,
                historical_context=context.historical_context + threat_context,
                urgency_level=context.urgency_level,
                confidence_threshold=context.confidence_threshold
            )
            
        except Exception as e:
            logger.error(f"Context enhancement failed: {e}")
            return context
    
    async def _make_intelligent_decision(
        self,
        decision_type: Any,
        context: Any,
        model: Any
    ) -> Dict[str, Any]:
        """Make intelligent decision based on real analysis."""
        
        # Get types at runtime
        DecisionType, ModelType = _get_decision_types()
        
        # Route to specialized decision handlers
        decision_handlers = {
            DecisionType.TASK_PRIORITIZATION: self._decide_task_prioritization,
            DecisionType.THREAT_CLASSIFICATION: self._decide_threat_classification,
            DecisionType.RISK_ASSESSMENT: self._decide_risk_assessment,
            DecisionType.RESPONSE_STRATEGY: self._decide_response_strategy,
            DecisionType.AGENT_ASSIGNMENT: self._decide_agent_assignment,
            DecisionType.RESOURCE_ALLOCATION: self._decide_resource_allocation,
            DecisionType.ORCHESTRATION_OPTIMIZATION: self._decide_orchestration_optimization,
            DecisionType.SECURITY_POSTURE: self._decide_security_posture
        }
        
        handler = decision_handlers.get(decision_type, self._decide_generic)
        return await handler(context, model)
    
    async def _decide_task_prioritization(
        self, 
        context: Any, 
        model: Any
    ) -> Dict[str, Any]:
        """Real task prioritization using threat intelligence."""
        
        tasks = context.available_data.get("tasks", [])
        recent_threats = context.available_data.get("recent_threats", [])
        tenant_risk_score = context.available_data.get("tenant_risk_score", 0.5)
        
        # Calculate priority scores
        priority_matrix = []
        
        for task in tasks:
            priority_score = 0.5  # Base priority
            
            # Boost priority for security-related tasks
            if any(keyword in str(task).lower() for keyword in ["security", "threat", "vulnerability", "incident"]):
                priority_score += 0.3
            
            # Boost based on tenant risk score
            priority_score += tenant_risk_score * 0.2
            
            # Boost if related to recent threats
            if recent_threats:
                for threat in recent_threats[-3:]:  # Last 3 threats
                    if threat.get("severity") in ["high", "critical"]:
                        priority_score += 0.2
                        break
            
            # Cap at 1.0
            priority_score = min(priority_score, 1.0)
            
            priority_matrix.append({
                "task": task,
                "priority_score": priority_score
            })
        
        # Sort by priority
        priority_matrix.sort(key=lambda x: x["priority_score"], reverse=True)
        
        high_priority_tasks = [t["task"] for t in priority_matrix[:3]]
        
        return {
            "recommendation": f"prioritize_tasks: {', '.join(map(str, high_priority_tasks[:2]))}",
            "confidence": 0.85,
            "reasoning": [
                f"Analyzed {len(tasks)} tasks using threat intelligence",
                f"Tenant risk score: {tenant_risk_score:.2f}",
                f"Recent threats considered: {len(recent_threats)}",
                "Prioritized security-critical tasks higher"
            ],
            "evidence": {
                "priority_matrix": priority_matrix,
                "tenant_risk_score": tenant_risk_score
            },
            "alternatives": [
                {"strategy": "parallel_processing", "confidence": 0.75},
                {"strategy": "time_based_priority", "confidence": 0.65}
            ]
        }
    
    async def _decide_threat_classification(
        self, 
        context: Any, 
        model: Any
    ) -> Dict[str, Any]:
        """Real threat classification using ML and threat intelligence."""
        
        indicators = context.available_data.get("indicators", [])
        severity_score = context.available_data.get("severity_score", 0.5)
        recent_threats = context.available_data.get("recent_threats", [])
        similar_cases = context.available_data.get("similar_cases", [])
        
        # Classification logic based on multiple factors
        classification_score = severity_score
        confidence = 0.7
        
        # Boost classification based on indicators
        if indicators:
            indicator_boost = len(indicators) * 0.1
            classification_score += indicator_boost
            confidence += 0.05
        
        # Consider similar historical cases
        if similar_cases:
            similar_high_severity = sum(1 for case in similar_cases if case.get("severity") in ["high", "critical"])
            if similar_high_severity > 0:
                classification_score += 0.2
                confidence += 0.1
        
        # Check recent threat patterns
        recent_critical = sum(1 for threat in recent_threats if threat.get("severity") == "critical")
        if recent_critical > 0:
            classification_score += 0.15
            confidence += 0.05
        
        # Determine classification
        if classification_score >= 0.9:
            classification = "critical_threat"
            urgency = "immediate"
        elif classification_score >= 0.7:
            classification = "high_severity_threat"
            urgency = "urgent"
        elif classification_score >= 0.5:
            classification = "medium_severity_threat"
            urgency = "normal"
        else:
            classification = "low_severity_incident"
            urgency = "routine"
        
        return {
            "recommendation": f"classify_as_{classification}",
            "confidence": min(confidence, 1.0),
            "reasoning": [
                f"Base severity score: {severity_score:.2f}",
                f"Indicators analyzed: {len(indicators)}",
                f"Similar cases found: {len(similar_cases)}",
                f"Recent critical threats: {recent_critical}",
                f"Final classification score: {classification_score:.2f}"
            ],
            "evidence": {
                "classification_score": classification_score,
                "urgency_level": urgency,
                "contributing_factors": {
                    "severity_score": severity_score,
                    "indicators_count": len(indicators),
                    "similar_cases": len(similar_cases),
                    "recent_criticals": recent_critical
                }
            },
            "alternatives": [
                {"classification": "escalate_for_review", "confidence": 0.6},
                {"classification": "automated_mitigation", "confidence": 0.7}
            ]
        }
    
    async def _decide_risk_assessment(
        self, 
        context: Any, 
        model: Any
    ) -> Dict[str, Any]:
        """Comprehensive risk assessment."""
        
        tenant_risk_score = context.available_data.get("tenant_risk_score", 0.5)
        recent_threats = context.available_data.get("recent_threats", [])
        similar_cases = context.available_data.get("similar_cases", [])
        
        # Risk calculation
        base_risk = tenant_risk_score
        threat_multiplier = 1.0
        
        # Adjust based on recent threat activity
        high_severity_threats = sum(1 for t in recent_threats if t.get("severity") in ["high", "critical"])
        if high_severity_threats > 0:
            threat_multiplier += high_severity_threats * 0.2
        
        # Factor in historical patterns
        if similar_cases:
            avg_severity = sum(1 for case in similar_cases if case.get("severity") in ["high", "critical"]) / len(similar_cases)
            threat_multiplier += avg_severity * 0.3
        
        final_risk_score = min(base_risk * threat_multiplier, 1.0)
        
        if final_risk_score >= 0.8:
            risk_level = "critical"
            recommendation = "immediate_risk_mitigation"
        elif final_risk_score >= 0.6:
            risk_level = "high"
            recommendation = "enhanced_monitoring"
        elif final_risk_score >= 0.4:
            risk_level = "medium"
            recommendation = "routine_monitoring"
        else:
            risk_level = "low"
            recommendation = "standard_procedures"
        
        return {
            "recommendation": recommendation,
            "confidence": 0.82,
            "reasoning": [
                f"Base tenant risk: {tenant_risk_score:.2f}",
                f"Recent high/critical threats: {high_severity_threats}",
                f"Risk multiplier: {threat_multiplier:.2f}",
                f"Final risk score: {final_risk_score:.2f}"
            ],
            "evidence": {
                "risk_level": risk_level,
                "risk_score": final_risk_score,
                "threat_activity": high_severity_threats,
                "historical_context": len(similar_cases)
            }
        }
    
    async def _decide_response_strategy(
        self, 
        context: Any, 
        model: Any
    ) -> Dict[str, Any]:
        """Real response strategy based on threat analysis."""
        
        threat_level = context.available_data.get("threat_level", "medium")
        available_actions = context.available_data.get("available_actions", [])
        tenant_risk_score = context.available_data.get("tenant_risk_score", 0.5)
        
        # Strategy selection logic
        if threat_level == "critical" or tenant_risk_score > 0.8:
            strategy = "immediate_containment"
            confidence = 0.95
            actions = ["isolate_affected_systems", "activate_incident_response", "notify_stakeholders"]
        elif threat_level == "high" or tenant_risk_score > 0.6:
            strategy = "rapid_response"
            confidence = 0.88
            actions = ["enhanced_monitoring", "prepare_containment", "gather_intelligence"]
        elif threat_level == "medium":
            strategy = "controlled_response"
            confidence = 0.82
            actions = ["investigate_further", "update_defenses", "monitor_closely"]
        else:
            strategy = "standard_monitoring"
            confidence = 0.75
            actions = ["routine_analysis", "update_signatures", "document_findings"]
        
        return {
            "recommendation": strategy,
            "confidence": confidence,
            "reasoning": [
                f"Threat level assessment: {threat_level}",
                f"Tenant risk score: {tenant_risk_score:.2f}",
                f"Available response actions: {len(available_actions)}",
                f"Strategy selected based on risk matrix"
            ],
            "evidence": {
                "recommended_actions": actions,
                "threat_level": threat_level,
                "risk_score": tenant_risk_score
            },
            "alternatives": [
                {"strategy": "escalate_to_human", "confidence": 0.7},
                {"strategy": "automated_mitigation", "confidence": 0.65}
            ]
        }
    
    async def _decide_agent_assignment(
        self, 
        context: Any, 
        model: Any
    ) -> Dict[str, Any]:
        """Intelligent agent assignment based on capabilities."""
        
        available_agents = context.available_data.get("agents", [])
        task_requirements = context.available_data.get("task_requirements", {})
        
        if not available_agents:
            return {
                "recommendation": "no_agents_available",
                "confidence": 0.9,
                "reasoning": ["No agents currently available for assignment"]
            }
        
        # Score agents based on task requirements
        agent_scores = []
        for agent in available_agents:
            score = 0.5  # Base score
            
            # Match capabilities (simplified scoring)
            if isinstance(agent, dict):
                agent_caps = agent.get("capabilities", [])
                required_caps = task_requirements.get("required_capabilities", [])
                
                if required_caps:
                    matches = len(set(agent_caps) & set(required_caps))
                    score += (matches / len(required_caps)) * 0.4
                
                # Consider agent load
                current_load = agent.get("current_load", 0.5)
                score += (1.0 - current_load) * 0.3
                
                agent_scores.append({
                    "agent": agent.get("id", agent),
                    "score": score,
                    "load": current_load,
                    "capabilities": agent_caps
                })
        
        # Select best agent
        if agent_scores:
            best_agent = max(agent_scores, key=lambda x: x["score"])
            
            return {
                "recommendation": f"assign_to_{best_agent['agent']}",
                "confidence": 0.85,
                "reasoning": [
                    f"Evaluated {len(available_agents)} available agents",
                    f"Best match score: {best_agent['score']:.2f}",
                    f"Agent current load: {best_agent['load']:.2f}",
                    "Selected based on capability match and availability"
                ],
                "evidence": {
                    "selected_agent": best_agent,
                    "all_scores": agent_scores
                }
            }
        
        return {
            "recommendation": f"assign_to_{available_agents[0]}",
            "confidence": 0.6,
            "reasoning": ["Fallback assignment to first available agent"]
        }
    
    async def _decide_resource_allocation(
        self, 
        context: Any, 
        model: Any
    ) -> Dict[str, Any]:
        """Smart resource allocation based on current load and priorities."""
        
        current_load = context.available_data.get("system_load", 0.5)
        pending_tasks = context.available_data.get("pending_tasks", 0)
        available_resources = context.available_data.get("available_resources", {})
        
        # Allocation strategy
        if current_load > 0.8:
            strategy = "scale_out_resources"
            confidence = 0.9
        elif pending_tasks > 50:
            strategy = "prioritize_critical_tasks"
            confidence = 0.85
        else:
            strategy = "maintain_current_allocation"
            confidence = 0.8
        
        return {
            "recommendation": strategy,
            "confidence": confidence,
            "reasoning": [
                f"System load: {current_load:.2f}",
                f"Pending tasks: {pending_tasks}",
                f"Available resources: {len(available_resources)}",
                "Allocation optimized for current conditions"
            ]
        }
    
    async def _decide_orchestration_optimization(
        self, 
        context: Any, 
        model: Any
    ) -> Dict[str, Any]:
        """Orchestration optimization decisions."""
        
        current_load = context.available_data.get("system_load", 0.5)
        pending_tasks = context.available_data.get("pending_tasks", 0)
        
        if current_load > 0.8:
            recommendation = "load_balancing_optimization"
            confidence = 0.92
        elif pending_tasks > 50:
            recommendation = "parallel_processing_boost"
            confidence = 0.88
        else:
            recommendation = "maintain_optimal_flow"
            confidence = 0.8
        
        return {
            "recommendation": recommendation,
            "confidence": confidence,
            "reasoning": [
                f"Current system load: {current_load:.2f}",
                f"Pending tasks: {pending_tasks}",
                "Orchestration optimized for performance"
            ]
        }
    
    async def _decide_security_posture(
        self, 
        context: Any, 
        model: Any
    ) -> Dict[str, Any]:
        """Security posture assessment and recommendations."""
        
        recent_threats = context.available_data.get("recent_threats", [])
        tenant_risk_score = context.available_data.get("tenant_risk_score", 0.5)
        
        critical_threats = sum(1 for t in recent_threats if t.get("severity") == "critical")
        
        if critical_threats > 0 or tenant_risk_score > 0.8:
            posture = "strengthen_defenses"
            confidence = 0.9
        elif tenant_risk_score > 0.6:
            posture = "enhance_monitoring" 
            confidence = 0.85
        else:
            posture = "maintain_current_posture"
            confidence = 0.8
        
        return {
            "recommendation": posture,
            "confidence": confidence,
            "reasoning": [
                f"Recent critical threats: {critical_threats}",
                f"Tenant risk score: {tenant_risk_score:.2f}",
                "Posture adjusted based on threat landscape"
            ]
        }
    
    async def _decide_generic(
        self, 
        context: Any, 
        model: Any
    ) -> Dict[str, Any]:
        """Generic decision handler for unknown types."""
        
        return {
            "recommendation": "analyze_and_recommend",
            "confidence": 0.7,
            "reasoning": [
                "Applied general decision framework",
                "Considered available context data",
                "Conservative approach for unknown scenario type"
            ],
            "evidence": {
                "context_data_keys": list(context.available_data.keys()),
                "scenario": context.scenario
            }
        }
    
    async def _calculate_tenant_risk_score(self, tenant_id: UUID) -> float:
        """Calculate real tenant risk score based on findings."""
        
        try:
            async with get_async_session() as session:
                # Get recent findings
                result = await session.execute(
                    select(Finding)
                    .where(
                        and_(
                            Finding.tenant_id == tenant_id,
                            Finding.created_at >= datetime.utcnow() - timedelta(days=30)
                        )
                    )
                )
                findings = result.scalars().all()
            
            if not findings:
                return 0.3  # Low baseline risk
            
            # Calculate risk based on findings severity
            risk_weights = {"critical": 1.0, "high": 0.7, "medium": 0.4, "low": 0.1}
            total_risk = sum(risk_weights.get(f.severity, 0.1) for f in findings)
            
            # Normalize to 0-1 scale (assume max 10 findings for normalization)
            normalized_risk = min(total_risk / 10.0, 1.0)
            
            return normalized_risk
            
        except Exception as e:
            logger.error(f"Risk score calculation failed: {e}")
            return 0.5  # Default medium risk
    
    async def _find_similar_scenarios(self, scenario: str, tenant_id: UUID) -> List[Dict]:
        """Find similar scenarios using vector search."""
        
        try:
            if not self.vector_store:
                return []
            
            # This would use vector similarity search in production
            # For now, return empty list as placeholder
            return []
            
        except Exception as e:
            logger.error(f"Similar scenario search failed: {e}")
            return []
    
    async def _store_decision(self, decision: Any, tenant_id: UUID):
        """Store decision for learning and analytics."""
        
        try:
            # In production, store decisions in database
            # For now, just log
            logger.info(f"Decision stored: {decision.decision_id} for tenant {tenant_id}")
            
        except Exception as e:
            logger.error(f"Decision storage failed: {e}")
    
    async def _create_fallback_decision(
        self, 
        request: Any, 
        decision_id: str, 
        start_time: datetime
    ) -> Any:
        """Create fallback decision when processing fails."""
        
        DecisionResponse = _get_response_type()
        return DecisionResponse(
            decision_id=decision_id,
            decision_type=request.decision_type,
            recommendation="manual_review_required",
            alternatives=[{"recommendation": "escalate_to_human", "confidence": 0.8}],
            confidence_score=0.5,
            reasoning=["Processing failed, manual review required"],
            supporting_evidence={"error": "processing_failed"},
            model_used=_get_decision_types()[1].QWEN3_ORCHESTRATOR,
            processing_time_ms=100,
            timestamp=start_time,
            expires_at=start_time + timedelta(hours=1)
        )